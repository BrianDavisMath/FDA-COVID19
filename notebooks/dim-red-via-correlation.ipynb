{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation-based feature selection\n",
    "\n",
    "This notebook takes the outptut of **centroid-sampling.pynb** and removes columns that are highly correlated (_>70%_)with other columns.\n",
    "\n",
    "The process is as follows:\n",
    "\n",
    "* identify the columns from each sub data set, e.g. fingerprints and binding-sites\n",
    "* extract a subset, consiting of those columns from the centroid-sampled set (this limits cardinality)\n",
    "* use the _Deepgraph_ code to  measure pairwise correlations across a random sample of 1,000 rows, across those columns. Retain the highly correlated column pairs.\n",
    "* calculate pairwise correlation across all rows for the retained columns\n",
    "* take one column from each remaining pair that are highly correlated\n",
    "* remove all remaining highly-correlated columns from the data set and save back to file\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(25000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 25 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/deepgraph/deepgraph.py:53: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  mpl.use('Agg')\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%autosave 25\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import deepgraph as dg\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = '../data/FDA-COVID19_files_v1.0/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data set output from centroid-sampling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 19,632, columns: 16,371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>pid</th>\n",
       "      <th>activity</th>\n",
       "      <th>AEK</th>\n",
       "      <th>VEL</th>\n",
       "      <th>EKF</th>\n",
       "      <th>LGM</th>\n",
       "      <th>VKN</th>\n",
       "      <th>LKP</th>\n",
       "      <th>NEE</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204106</td>\n",
       "      <td>Q9UP65</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204106</td>\n",
       "      <td>P47712</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10290302</td>\n",
       "      <td>P00403</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10290302</td>\n",
       "      <td>P00395</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>46938678</td>\n",
       "      <td>O15528</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 16371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cid     pid  activity  AEK  VEL  EKF  LGM  VKN  LKP  NEE  ...  4086  \\\n",
       "0    204106  Q9UP65         1 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ...     0   \n",
       "1    204106  P47712         0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ...     0   \n",
       "3  10290302  P00403         1 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ...     0   \n",
       "4  10290302  P00395         1 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ...     0   \n",
       "7  46938678  O15528         0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ...     0   \n",
       "\n",
       "   4087  4088  4089  4090  4091  4092  4093  4094  4095  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0     0     0  \n",
       "7     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 16371 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store = pd.HDFStore(data_loc + 'training_sampled_data.h5')\n",
    "df_features = pd.DataFrame(store['df' ])\n",
    "store.close()\n",
    "print('rows: {:,}, columns: {:,}'.format(len(df_features), len(df_features.columns)))\n",
    "\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get column names associated with a data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_names(file_name):\n",
    "    df = pd.read_csv(data_loc+file_name, index_col=0, nrows=0) # We need only the column names\n",
    "    df_cols = df.columns.tolist()\n",
    "    \n",
    "    # Take intersction with the most up to date, full feature set to drop those that have\n",
    "    # already been eliminated, e.g. because of zero variance columns removed in centroid-sampling.ipynb.\n",
    "    cols = df_features.columns.intersection(df_cols)\n",
    "    del df\n",
    "    del df_cols\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up old files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete old correlation files\n",
    "def clean_up():\n",
    "    subprocess.run('rm {}correlations/*'.format(data_loc), shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df_data):\n",
    "    # whiten variables for fast parallel computation later on\n",
    "    df_data = (df_data - df_data.mean(axis=1, keepdims=True)) / df_data.std(axis=1, keepdims=True)\n",
    "\n",
    "    # save in binary format\n",
    "    np.save(data_loc+'samples', df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data for subset of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_get_data(file_name, samples=None):\n",
    "    clean_up()\n",
    "    cols = get_col_names(file_name)\n",
    "    \n",
    "    if sample is None:\n",
    "        X =  df_features[cols].values.T\n",
    "    else:\n",
    "        X =  df_features[cols].sample(n=samples, random_state=23).values.T\n",
    "        \n",
    "    pre_process(X)\n",
    "    print('Data shape: {}.'.format(X.shape))\n",
    "    del X\n",
    "    \n",
    "    # load samples as memory-map\n",
    "    return (np.load(data_loc+'samples.npy', mmap_mode='r'), cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deepgraph parallel computation of Pearson's Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connector function to compute pairwise pearson correlations\n",
    "# index_s and index_t are equal length arrays of indices for pairwise correlation\n",
    "def corr(index_s, index_t):\n",
    "    features_s = X[index_s].T\n",
    "    features_t = X[index_t].T\n",
    "    \n",
    "    c = 1./(n_samples - 1)\n",
    "    cov_xy = c * np.dot(features_s.T, features_t)\n",
    "    var_x = c * np.sum(features_s**2, axis=0)\n",
    "    var_y = c * np.sum(features_t**2, axis=0)\n",
    "    corrcoef_xy = cov_xy / np.sqrt(var_x[:, None] * var_y[None,:])\n",
    "    corr = np.diag(corrcoef_xy)\n",
    "    \n",
    "    del cov_xy\n",
    "    del var_x\n",
    "    del var_y\n",
    "    del corrcoef_xy\n",
    "    \n",
    "    #if 1947 in index_t:\n",
    "    #    print('corrcoef_xy shape: {}, index_s shape: {}, index_t shape: {}'.format(corrcoef_xy.shape, index_s.shape, index_t.shape))\n",
    "    \n",
    "    return corr\n",
    "    \n",
    "\n",
    "# parallel computation\n",
    "def create_ei(i):\n",
    "    from_pos = pos_array[i]\n",
    "    to_pos = pos_array[i+1]\n",
    "\n",
    "    # initiate DeepGraph\n",
    "    g = dg.DeepGraph(v)\n",
    "\n",
    "    # create edges\n",
    "    g.create_edges(connectors=corr, step_size=step_size,\n",
    "                   from_pos=from_pos, to_pos=to_pos)\n",
    "\n",
    "    # store edge table\n",
    "    g.e.to_pickle((data_loc+'correlations/{}.pickle').format(str(i).zfill(3)))\n",
    "\n",
    "\n",
    "# computation\n",
    "def calculate_correlation():\n",
    "    os.makedirs(data_loc+'correlations/', exist_ok=True)\n",
    "    indices = np.arange(0, n_processes - 1)\n",
    "    p = Pool()\n",
    "    for _ in p.imap_unordered(create_ei, indices):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_results():\n",
    "    # store correlation values\n",
    "    files = os.listdir(data_loc+'correlations/')\n",
    "    files.sort()\n",
    "    store = pd.HDFStore(data_loc+'e.h5', mode='w')\n",
    "    for f in files:\n",
    "        #print((data_loc+'correlations/{}').format(f))\n",
    "        et = pd.read_pickle((data_loc+'correlations/{}').format(f))\n",
    "        store.append('e', et, format='t', data_columns=True, index=False)\n",
    "    store.close()\n",
    "    \n",
    "    # load correlation table\n",
    "    e = pd.read_hdf(data_loc+'e.h5')\n",
    "    \n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highly_correlated_col_names(df_corr, cols):\n",
    "    pairs = list(df_corr.index)\n",
    "    p1 = [s for (s, t) in pairs]\n",
    "    p2 = [t for (s, t) in pairs]\n",
    "    \n",
    "    c = set(p1 + p2)\n",
    "    print('There are {:,} highly correlated columns for this set.'.format(len(c)))\n",
    "\n",
    "    col_names = [cols[i] for i in c]\n",
    "    return col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_to_drop(df_corr, cols):\n",
    "    pairs = list(df_corr.index)\n",
    "    p2 = set([t for (s, t) in pairs])\n",
    "\n",
    "    print('Dropping {:,} columns.'.format(len(p2)))\n",
    "\n",
    "    cols_to_drop = [cols[i] for i in p2]\n",
    "    return cols_to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set of columns names to drop from first pass\n",
    "\n",
    "These are our candidates from the random 1000 row samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols_first_pass = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAM control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 5e2\n",
    "n_processes = 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drug_features/fingerprints.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (4096, 1000).\n",
      "Number of highly correlated column pairs: 16\n",
      "There are 32 highly correlated columns for this set.\n"
     ]
    }
   ],
   "source": [
    "(X, cols) = get_get_data('drug_features/fingerprints.csv', samples=1000)\n",
    "\n",
    "n_features = len(X)\n",
    "n_samples = len(X[1])\n",
    "\n",
    "# index array for parallelization\n",
    "pos_array = np.array(np.linspace(0, n_features*(n_features-1)//2, n_processes), dtype=int)\n",
    "\n",
    "# create node table that stores references to the mem-mapped samples\n",
    "v = pd.DataFrame({'index': range(X.shape[0])})\n",
    "\n",
    "calculate_correlation()\n",
    "del v\n",
    "del X\n",
    "\n",
    "res = retrieve_results().abs()\n",
    "finger_print_corr = res[res['corr'] > 0.7]\n",
    "print('Number of highly correlated column pairs: {:,}'.format(len(finger_print_corr)))\n",
    "\n",
    "drop_cols_first_pass = drop_cols_first_pass + get_highly_correlated_col_names(finger_print_corr, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drug_features/dragon_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (2960, 1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of highly correlated column pairs: 317,491\n",
      "There are 2,339 highly correlated columns for this set.\n"
     ]
    }
   ],
   "source": [
    "(X, cols) = get_get_data('drug_features/dragon_features.csv', samples=1000)\n",
    "\n",
    "n_features = len(X)\n",
    "n_samples = len(X[1])\n",
    "\n",
    "# index array for parallelization\n",
    "pos_array = np.array(np.linspace(0, n_features*(n_features-1)//2, n_processes), dtype=int)\n",
    "\n",
    "# create node table that stores references to the mem-mapped samples\n",
    "v = pd.DataFrame({'index': range(X.shape[0])})\n",
    "\n",
    "calculate_correlation()\n",
    "del v\n",
    "del X\n",
    "\n",
    "res = retrieve_results().abs()\n",
    "dragon_features_corr = res[res['corr'] > 0.7]\n",
    "print('Number of highly correlated column pairs: {:,}'.format(len(dragon_features_corr)))\n",
    "\n",
    "drop_cols_first_pass = drop_cols_first_pass + get_highly_correlated_col_names(dragon_features_corr, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x12cea9d30>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res.hist(bins=1000, figsize=(10,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### protein_features/binding_sites_v1.0.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (8409, 1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of highly correlated column pairs: 2,772\n",
      "There are 1,120 highly correlated columns for this set.\n"
     ]
    }
   ],
   "source": [
    "(X, cols) = get_get_data('protein_features/binding_sites_v1.0.csv', samples=1000)\n",
    "\n",
    "n_features = len(X)\n",
    "n_samples = len(X[1])\n",
    "\n",
    "# index array for parallelization\n",
    "pos_array = np.array(np.linspace(0, n_features*(n_features-1)//2, n_processes), dtype=int)\n",
    "\n",
    "# create node table that stores references to the mem-mapped samples\n",
    "v = pd.DataFrame({'index': range(X.shape[0])})\n",
    "\n",
    "calculate_correlation()\n",
    "del v\n",
    "del X\n",
    "\n",
    "res = retrieve_results().abs()\n",
    "binding_sites_corr = res[res['corr'] > 0.9]\n",
    "print('Number of highly correlated column pairs: {:,}'.format(len(binding_sites_corr)))\n",
    "\n",
    "drop_cols_first_pass = drop_cols_first_pass + get_highly_correlated_col_names(binding_sites_corr, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### protein_features/expasy.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(X, cols) = get_get_data('protein_features/expasy.csv', samples=1000)\\n\\nn_features = len(X)\\nn_samples = len(X[1])\\n\\n# index array for parallelization\\npos_array = np.array(np.linspace(0, n_features*(n_features-1)//2, n_processes), dtype=int)\\n\\n# create node table that stores references to the mem-mapped samples\\nv = pd.DataFrame({'index': range(X.shape[0])})\\n\\ncalculate_correlation()\\ndel v\\ndel X\\n\\nres = retrieve_results().abs()\\nexpasy_corr = res[res['corr'] > 0.9]\\nprint('Number of highly correlated column pairs: {:,}'.format(len(expasy_corr)))\\n\\ndrop_cols = drop_cols + get_highly_correlated_col_names(expasy_corr, cols)\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can skip this given that there're hardly any columns in this data set\n",
    "\n",
    "'''(X, cols) = get_get_data('protein_features/expasy.csv', samples=1000)\n",
    "\n",
    "n_features = len(X)\n",
    "n_samples = len(X[1])\n",
    "\n",
    "# index array for parallelization\n",
    "pos_array = np.array(np.linspace(0, n_features*(n_features-1)//2, n_processes), dtype=int)\n",
    "\n",
    "# create node table that stores references to the mem-mapped samples\n",
    "v = pd.DataFrame({'index': range(X.shape[0])})\n",
    "\n",
    "calculate_correlation()\n",
    "del v\n",
    "del X\n",
    "\n",
    "res = retrieve_results().abs()\n",
    "expasy_corr = res[res['corr'] > 0.9]\n",
    "print('Number of highly correlated column pairs: {:,}'.format(len(expasy_corr)))\n",
    "\n",
    "drop_cols = drop_cols + get_highly_correlated_col_names(expasy_corr, cols)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### protein_features/profeat.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (849, 1000).\n",
      "Number of highly correlated column pairs: 2,479\n",
      "There are 364 highly correlated columns for this set.\n"
     ]
    }
   ],
   "source": [
    "(X, cols) = get_get_data('protein_features/profeat.csv', samples=1000)\n",
    "\n",
    "n_features = len(X)\n",
    "n_samples = len(X[1])\n",
    "\n",
    "# index array for parallelization\n",
    "pos_array = np.array(np.linspace(0, n_features*(n_features-1)//2, n_processes), dtype=int)\n",
    "\n",
    "# create node table that stores references to the mem-mapped samples\n",
    "v = pd.DataFrame({'index': range(X.shape[0])})\n",
    "\n",
    "calculate_correlation()\n",
    "del v\n",
    "del X\n",
    "\n",
    "res = retrieve_results().abs()\n",
    "profeat_corr = res[res['corr'] > 0.7]\n",
    "print('Number of highly correlated column pairs: {:,}'.format(len(profeat_corr)))\n",
    "\n",
    "drop_cols_first_pass = drop_cols_first_pass + get_highly_correlated_col_names(profeat_corr, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### protein_features/porter.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(X, cols) = get_get_data('protein_features/porter.csv', samples=1000)\\n\\nn_features = len(X)\\nn_samples = len(X[1])\\n\\n# index array for parallelization\\npos_array = np.array(np.linspace(0, n_features*(n_features-1)//2, n_processes), dtype=int)\\n\\n# create node table that stores references to the mem-mapped samples\\nv = pd.DataFrame({'index': range(X.shape[0])})\\n\\ncalculate_correlation()\\ndel v\\ndel X\\n\\nres = retrieve_results().abs()\\nporter_corr = res[res['corr'] > 0.9]\\nprint('Number of highly correlated column pairs: {:,}'.format(len(porter_corr)))\\n\\ndrop_cols = drop_cols + get_highly_correlated_col_names(porter_corr, cols)\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can skip this given that there're hardly any columns in this data set\n",
    "\n",
    "'''(X, cols) = get_get_data('protein_features/porter.csv', samples=1000)\n",
    "\n",
    "n_features = len(X)\n",
    "n_samples = len(X[1])\n",
    "\n",
    "# index array for parallelization\n",
    "pos_array = np.array(np.linspace(0, n_features*(n_features-1)//2, n_processes), dtype=int)\n",
    "\n",
    "# create node table that stores references to the mem-mapped samples\n",
    "v = pd.DataFrame({'index': range(X.shape[0])})\n",
    "\n",
    "calculate_correlation()\n",
    "del v\n",
    "del X\n",
    "\n",
    "res = retrieve_results().abs()\n",
    "porter_corr = res[res['corr'] > 0.9]\n",
    "print('Number of highly correlated column pairs: {:,}'.format(len(porter_corr)))\n",
    "\n",
    "drop_cols = drop_cols + get_highly_correlated_col_names(porter_corr, cols)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd pass\n",
    "\n",
    "Given all of the highly correlated columns in across the random n rows, re-test that set across all rows. The smaller set of columns should make it quite fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3,855 highly correlated columns across the data set.\n",
      "Data shape: (3855, 19632).\n",
      "Number of highly correlated column pairs: 282,685\n",
      "Dropping 2,520 columns.\n",
      "number of columns to drop: 2,520\n"
     ]
    }
   ],
   "source": [
    "print('There are {:,} highly correlated columns across the data set.'.format(len(drop_cols_first_pass)))\n",
    "\n",
    "clean_up()\n",
    "X =  df_features[drop_cols_first_pass].values.T\n",
    "    \n",
    "pre_process(X)\n",
    "print('Data shape: {}.'.format(X.shape))\n",
    "del X\n",
    "\n",
    "# load samples as memory-map\n",
    "X = np.load(data_loc+'samples.npy', mmap_mode='r')\n",
    "\n",
    "n_features = len(X)\n",
    "n_samples = len(X[1])\n",
    "\n",
    "# index array for parallelization\n",
    "pos_array = np.array(np.linspace(0, n_features*(n_features-1)//2, n_processes), dtype=int)\n",
    "\n",
    "# create node table that stores references to the mem-mapped samples\n",
    "v = pd.DataFrame({'index': range(X.shape[0])})\n",
    "\n",
    "calculate_correlation()\n",
    "del v\n",
    "del X\n",
    "\n",
    "res = retrieve_results().abs()\n",
    "df_corr = res[res['corr'] > 0.7]\n",
    "print('Number of highly correlated column pairs: {:,}'.format(len(df_corr)))\n",
    "\n",
    "cols_to_drop = get_cols_to_drop(df_corr, drop_cols_first_pass)\n",
    "\n",
    "print('number of columns to drop: {:,}'.format(len(cols_to_drop)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the new data set without the correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_features.drop(cols_to_drop, axis=1)\n",
    "store = pd.HDFStore(data_loc + 'training_sampled_data.h5')\n",
    "store['df'] = df\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19632, 13851)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
