{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation-based feature selection\n",
    "\n",
    "This notebook takes the outptut of **centroid-sampling.pynb** and removes columns that are highly correlated (_>70%_)with other columns.\n",
    "\n",
    "The process is as follows:\n",
    "\n",
    "* identify the columns from each sub data set, e.g. fingerprints and binding-sites\n",
    "* extract a subset, consiting of those columns from the centroid-sampled set (this limits cardinality)\n",
    "* use the _Deepgraph_ code to  measure pairwise correlations across a random sample of 1,000 rows, across those columns. Retain the highly correlated column pairs.\n",
    "* calculate pairwise correlation across all rows for the retained columns\n",
    "* take one column from each remaining pair that are highly correlated\n",
    "* remove all remaining highly-correlated columns from the data set and save back to file\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%autosave 25\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import deepgraph as dg\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = '../data/FDA-COVID19_files_v1.0/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data set output from centroid-sampling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 22,172, columns: 14,730\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>pid</th>\n",
       "      <th>activity</th>\n",
       "      <th>AEK</th>\n",
       "      <th>VEL</th>\n",
       "      <th>EKF</th>\n",
       "      <th>LGM</th>\n",
       "      <th>VKN</th>\n",
       "      <th>LKP</th>\n",
       "      <th>NEE</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>204</td>\n",
       "      <td>Q99VQ4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>204</td>\n",
       "      <td>EDT84149</td>\n",
       "      <td>0</td>\n",
       "      <td>3.936758</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>204</td>\n",
       "      <td>AAX80043</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>204</td>\n",
       "      <td>P0C6X7</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.367871</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>8549</td>\n",
       "      <td>P08659</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 14730 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cid       pid  activity       AEK  VEL  EKF  LGM  VKN  LKP       NEE  \\\n",
       "58    204    Q99VQ4         1 -1.000000 -1.0 -1.0 -1.0 -1.0 -1.0 -1.000000   \n",
       "97    204  EDT84149         0  3.936758 -1.0 -1.0 -1.0 -1.0 -1.0 -1.000000   \n",
       "98    204  AAX80043         0 -1.000000 -1.0 -1.0 -1.0 -1.0 -1.0 -1.000000   \n",
       "126   204    P0C6X7         1 -1.000000 -1.0 -1.0 -1.0 -1.0 -1.0  2.367871   \n",
       "136  8549    P08659         0 -1.000000 -1.0 -1.0 -1.0 -1.0 -1.0 -1.000000   \n",
       "\n",
       "     ...   4086  4087  4088  4089  4090  4091  4092  4093  4094  4095  \n",
       "58   ...      0     0     0     0     0     0     0     0     0     0  \n",
       "97   ...      0     0     0     0     0     0     0     0     0     0  \n",
       "98   ...      0     0     0     0     0     0     0     0     0     0  \n",
       "126  ...      0     0     0     0     0     0     0     0     0     0  \n",
       "136  ...      0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 14730 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store = pd.HDFStore(data_loc + 'sampled_data.h5')\n",
    "df_features = pd.DataFrame(store['df' ])\n",
    "store.close()\n",
    "print('rows: {:,}, columns: {:,}'.format(len(df_features), len(df_features.columns)))\n",
    "\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get column names associated with a data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_names(file_name):\n",
    "    df = pd.read_csv(data_loc+file_name, index_col=0, nrows=0) # We need only the column names\n",
    "    df_cols = df.columns.tolist()\n",
    "    \n",
    "    # Take intersction with the most up to date, full feature set to drop those that have\n",
    "    # already been eliminated, e.g. because of zero variance columns removed in centroid-sampling.ipynb.\n",
    "    cols = df_features.columns.intersection(df_cols)\n",
    "    del df\n",
    "    del df_cols\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up old files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete old correlation files\n",
    "def clean_up():\n",
    "    subprocess.run('rm {}correlations/*'.format(data_loc), shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df_data):\n",
    "    # whiten variables for fast parallel computation later on\n",
    "    df_data = (df_data - df_data.mean(axis=1, keepdims=True)) / df_data.std(axis=1, keepdims=True)\n",
    "\n",
    "    # save in binary format\n",
    "    np.save(data_loc+'samples', df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data for subset of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_get_data(file_name, samples=None):\n",
    "    clean_up()\n",
    "    cols = get_col_names(file_name)\n",
    "    \n",
    "    if sample is None:\n",
    "        X =  df_features[cols].values.T\n",
    "    else:\n",
    "        X =  df_features[cols].sample(n=samples, random_state=23).values.T\n",
    "        \n",
    "    pre_process(X)\n",
    "    print('Data shape: {}.'.format(X.shape))\n",
    "    del X\n",
    "    \n",
    "    # load samples as memory-map\n",
    "    return (np.load(data_loc+'samples.npy', mmap_mode='r'), cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deepgraph parallel computation of Pearson's Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connector function to compute pairwise pearson correlations\n",
    "# index_s and index_t are equal length arrays of indices for pairwise correlation\n",
    "def corr(index_s, index_t):\n",
    "    features_s = X[index_s].T\n",
    "    features_t = X[index_t].T\n",
    "    \n",
    "    c = 1./(n_samples - 1)\n",
    "    cov_xy = c * np.dot(features_s.T, features_t)\n",
    "    var_x = c * np.sum(features_s**2, axis=0)\n",
    "    var_y = c * np.sum(features_t**2, axis=0)\n",
    "    corrcoef_xy = cov_xy / np.sqrt(var_x[:, None] * var_y[None,:])\n",
    "    corr = np.diag(corrcoef_xy)\n",
    "    \n",
    "    del cov_xy\n",
    "    del var_x\n",
    "    del var_y\n",
    "    del corrcoef_xy\n",
    "    \n",
    "    #if 1947 in index_t:\n",
    "    #    print('corrcoef_xy shape: {}, index_s shape: {}, index_t shape: {}'.format(corrcoef_xy.shape, index_s.shape, index_t.shape))\n",
    "    \n",
    "    return corr\n",
    "    \n",
    "\n",
    "# parallel computation\n",
    "def create_ei(i):\n",
    "    from_pos = pos_array[i]\n",
    "    to_pos = pos_array[i+1]\n",
    "\n",
    "    # initiate DeepGraph\n",
    "    g = dg.DeepGraph(v)\n",
    "\n",
    "    # create edges\n",
    "    g.create_edges(connectors=corr, step_size=step_size,\n",
    "                   from_pos=from_pos, to_pos=to_pos)\n",
    "\n",
    "    # store edge table\n",
    "    g.e.to_pickle((data_loc+'correlations/{}.pickle').format(str(i).zfill(3)))\n",
    "\n",
    "\n",
    "# computation\n",
    "def calculate_correlation():\n",
    "    os.makedirs(data_loc+'correlations/', exist_ok=True)\n",
    "    indices = np.arange(0, n_processes - 1)\n",
    "    p = Pool()\n",
    "    for _ in p.imap_unordered(create_ei, indices):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_results():\n",
    "    # store correlation values\n",
    "    files = os.listdir(data_loc+'correlations/')\n",
    "    files.sort()\n",
    "    store = pd.HDFStore(data_loc+'e.h5', mode='w')\n",
    "    for f in files:\n",
    "        #print((data_loc+'correlations/{}').format(f))\n",
    "        et = pd.read_pickle((data_loc+'correlations/{}').format(f))\n",
    "        store.append('e', et, format='t', data_columns=True, index=False)\n",
    "    store.close()\n",
    "    \n",
    "    # load correlation table\n",
    "    e = pd.read_hdf(data_loc+'e.h5')\n",
    "    \n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highly_correlated_col_names(df_corr, cols):\n",
    "    pairs = list(df_corr.index)\n",
    "    p1 = [s for (s, t) in pairs]\n",
    "    p2 = [t for (s, t) in pairs]\n",
    "    \n",
    "    c = set(p1 + p2)\n",
    "    print('There are {:,} highly correlated columns for this set.'.format(len(c)))\n",
    "\n",
    "    col_names = [cols[i] for i in c]\n",
    "    return col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_to_drop(df_corr, cols):\n",
    "    pairs = list(df_corr.index)\n",
    "    p2 = set([t for (s, t) in pairs])\n",
    "\n",
    "    print('Dropping {:,} columns.'.format(len(p2)))\n",
    "\n",
    "    cols_to_drop = [cols[i] for i in p2]\n",
    "    return cols_to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set of columns names to drop from first pass\n",
    "\n",
    "These are our candidates from the random 1000 row samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols_first_pass = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAM control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 5e2\n",
    "n_processes = 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drug_features/fingerprints.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (4094, 1000).\n",
      "Number of highly correlated column pairs: 18\n",
      "There are 33 highly correlated columns for this set.\n"
     ]
    }
   ],
   "source": [
    "(X, cols) = get_get_data('drug_features/fingerprints.csv', samples=1000)\n",
    "\n",
    "n_features = len(X)\n",
    "n_samples = len(X[1])\n",
    "\n",
    "# index array for parallelization\n",
    "pos_array = np.array(np.linspace(0, n_features*(n_features-1)//2, n_processes), dtype=int)\n",
    "\n",
    "# create node table that stores references to the mem-mapped samples\n",
    "v = pd.DataFrame({'index': range(X.shape[0])})\n",
    "\n",
    "calculate_correlation()\n",
    "del v\n",
    "del X\n",
    "\n",
    "res = retrieve_results().abs()\n",
    "finger_print_corr = res[res['corr'] > 0.7]\n",
    "print('Number of highly correlated column pairs: {:,}'.format(len(finger_print_corr)))\n",
    "\n",
    "drop_cols_first_pass = drop_cols_first_pass + get_highly_correlated_col_names(finger_print_corr, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drug_features/dragon_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1557, 1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of highly correlated column pairs: 2,206\n",
      "There are 931 highly correlated columns for this set.\n"
     ]
    }
   ],
   "source": [
    "(X, cols) = get_get_data('drug_features/dragon_features.csv', samples=1000)\n",
    "\n",
    "n_features = len(X)\n",
    "n_samples = len(X[1])\n",
    "\n",
    "# index array for parallelization\n",
    "pos_array = np.array(np.linspace(0, n_features*(n_features-1)//2, n_processes), dtype=int)\n",
    "\n",
    "# create node table that stores references to the mem-mapped samples\n",
    "v = pd.DataFrame({'index': range(X.shape[0])})\n",
    "\n",
    "calculate_correlation()\n",
    "del v\n",
    "del X\n",
    "\n",
    "res = retrieve_results().abs()\n",
    "dragon_features_corr = res[res['corr'] > 0.7]\n",
    "print('Number of highly correlated column pairs: {:,}'.format(len(dragon_features_corr)))\n",
    "\n",
    "drop_cols_first_pass = drop_cols_first_pass + get_highly_correlated_col_names(dragon_features_corr, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1251c7dd8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res.hist(bins=1000, figsize=(10,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### protein_features/binding_sites_v1.0.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (8308, 1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of highly correlated column pairs: 2,032\n",
      "There are 1,005 highly correlated columns for this set.\n"
     ]
    }
   ],
   "source": [
    "(X, cols) = get_get_data('protein_features/binding_sites_v1.0.csv', samples=1000)\n",
    "\n",
    "n_features = len(X)\n",
    "n_samples = len(X[1])\n",
    "\n",
    "# index array for parallelization\n",
    "pos_array = np.array(np.linspace(0, n_features*(n_features-1)//2, n_processes), dtype=int)\n",
    "\n",
    "# create node table that stores references to the mem-mapped samples\n",
    "v = pd.DataFrame({'index': range(X.shape[0])})\n",
    "\n",
    "calculate_correlation()\n",
    "del v\n",
    "del X\n",
    "\n",
    "res = retrieve_results().abs()\n",
    "binding_sites_corr = res[res['corr'] > 0.9]\n",
    "print('Number of highly correlated column pairs: {:,}'.format(len(binding_sites_corr)))\n",
    "\n",
    "drop_cols_first_pass = drop_cols_first_pass + get_highly_correlated_col_names(binding_sites_corr, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### protein_features/expasy.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can skip this given that there're hardly any columns in this data set\n",
    "\n",
    "'''(X, cols) = get_get_data('protein_features/expasy.csv', samples=1000)\n",
    "\n",
    "n_features = len(X)\n",
    "n_samples = len(X[1])\n",
    "\n",
    "# index array for parallelization\n",
    "pos_array = np.array(np.linspace(0, n_features*(n_features-1)//2, n_processes), dtype=int)\n",
    "\n",
    "# create node table that stores references to the mem-mapped samples\n",
    "v = pd.DataFrame({'index': range(X.shape[0])})\n",
    "\n",
    "calculate_correlation()\n",
    "del v\n",
    "del X\n",
    "\n",
    "res = retrieve_results().abs()\n",
    "expasy_corr = res[res['corr'] > 0.9]\n",
    "print('Number of highly correlated column pairs: {:,}'.format(len(expasy_corr)))\n",
    "\n",
    "drop_cols = drop_cols + get_highly_correlated_col_names(expasy_corr, cols)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### protein_features/profeat.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (714, 1000).\n",
      "Number of highly correlated column pairs: 207\n",
      "There are 197 highly correlated columns for this set.\n"
     ]
    }
   ],
   "source": [
    "(X, cols) = get_get_data('protein_features/profeat.csv', samples=1000)\n",
    "\n",
    "n_features = len(X)\n",
    "n_samples = len(X[1])\n",
    "\n",
    "# index array for parallelization\n",
    "pos_array = np.array(np.linspace(0, n_features*(n_features-1)//2, n_processes), dtype=int)\n",
    "\n",
    "# create node table that stores references to the mem-mapped samples\n",
    "v = pd.DataFrame({'index': range(X.shape[0])})\n",
    "\n",
    "calculate_correlation()\n",
    "del v\n",
    "del X\n",
    "\n",
    "res = retrieve_results().abs()\n",
    "profeat_corr = res[res['corr'] > 0.7]\n",
    "print('Number of highly correlated column pairs: {:,}'.format(len(profeat_corr)))\n",
    "\n",
    "drop_cols_first_pass = drop_cols_first_pass + get_highly_correlated_col_names(profeat_corr, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### protein_features/porter.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can skip this given that there're hardly any columns in this data set\n",
    "\n",
    "'''(X, cols) = get_get_data('protein_features/porter.csv', samples=1000)\n",
    "\n",
    "n_features = len(X)\n",
    "n_samples = len(X[1])\n",
    "\n",
    "# index array for parallelization\n",
    "pos_array = np.array(np.linspace(0, n_features*(n_features-1)//2, n_processes), dtype=int)\n",
    "\n",
    "# create node table that stores references to the mem-mapped samples\n",
    "v = pd.DataFrame({'index': range(X.shape[0])})\n",
    "\n",
    "calculate_correlation()\n",
    "del v\n",
    "del X\n",
    "\n",
    "res = retrieve_results().abs()\n",
    "porter_corr = res[res['corr'] > 0.9]\n",
    "print('Number of highly correlated column pairs: {:,}'.format(len(porter_corr)))\n",
    "\n",
    "drop_cols = drop_cols + get_highly_correlated_col_names(porter_corr, cols)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd pass\n",
    "\n",
    "Given all of the highly correlated columns in across the random n rows, re-test that set across all rows. The smaller set of columns should make it quite fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2,166 highly correlated columns across the data set.\n",
      "Data shape: (2166, 22172).\n",
      "Number of highly correlated column pairs: 2,394\n",
      "Dropping 879 columns.\n",
      "number of columns to drop: 879\n"
     ]
    }
   ],
   "source": [
    "print('There are {:,} highly correlated columns across the data set.'.format(len(drop_cols_first_pass)))\n",
    "\n",
    "clean_up()\n",
    "X =  df_features[drop_cols_first_pass].values.T\n",
    "    \n",
    "pre_process(X)\n",
    "print('Data shape: {}.'.format(X.shape))\n",
    "del X\n",
    "\n",
    "# load samples as memory-map\n",
    "X = np.load(data_loc+'samples.npy', mmap_mode='r')\n",
    "\n",
    "n_features = len(X)\n",
    "n_samples = len(X[1])\n",
    "\n",
    "# index array for parallelization\n",
    "pos_array = np.array(np.linspace(0, n_features*(n_features-1)//2, n_processes), dtype=int)\n",
    "\n",
    "# create node table that stores references to the mem-mapped samples\n",
    "v = pd.DataFrame({'index': range(X.shape[0])})\n",
    "\n",
    "calculate_correlation()\n",
    "del v\n",
    "del X\n",
    "\n",
    "res = retrieve_results().abs()\n",
    "df_corr = res[res['corr'] > 0.7]\n",
    "print('Number of highly correlated column pairs: {:,}'.format(len(df_corr)))\n",
    "\n",
    "cols_to_drop = get_cols_to_drop(df_corr, drop_cols_first_pass)\n",
    "\n",
    "print('number of columns to drop: {:,}'.format(len(cols_to_drop)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the new data set without the correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_features.drop(cols_to_drop, axis=1)\n",
    "store = pd.HDFStore(data_loc + 'sampled_data.h5')\n",
    "store['df'] = df\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22172, 13851)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
