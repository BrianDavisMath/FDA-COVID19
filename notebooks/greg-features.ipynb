{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation\n",
    "<hr>\n",
    "\n",
    "This notebook takes the protein and drug files, cleans them and stitches them together into training and validation feature sets.\n",
    "\n",
    "It assumes the data is in a sub-directory of the **/data** folder. I've already added entries to the _.gitignore_ file so that they won't be committed to the repository. Note that this file should be updated for new versions of the data.\n",
    "\n",
    "See the [data readme in the Gitbug repository](https://github.com/BrianDavisMath/FDA-COVID19/tree/master/data) for more details.\n",
    "\n",
    "The output is a file called **features.csv**\n",
    "\n",
    "<hr>\n",
    "\n",
    "**NOTE:** the finger prints and binding sites data are unzipped from the reduced/derived sets from here:\n",
    "\n",
    "* https://github.com/BrianDavisMath/FDA-COVID19/blob/master/data/reduced_binding_site_features_v2.zip\n",
    "* https://github.com/BrianDavisMath/FDA-COVID19/blob/master/data/reduced_fingerprints_v1.5.zip\n",
    "\n",
    "These into the corresponding drug-features and protein-features folder under the _data_loc_ directory.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(25000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 25 seconds\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%autosave 25\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data location\n",
    "\n",
    "Change this when you get a new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = '../data/FDA-COVID19_files_v1.0/'\n",
    "\n",
    "# The following directory is unipped from the file at: \n",
    "# https://github.com/BrianDavisMath/FDA-COVID19/blob/master/test_train_split/training_validation_split.zip\n",
    "interactions_data_loc = '../data/training_validation_split/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for loading data and merging\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load a specific features CSV file\n",
    "def load_data(path, data_type=None):\n",
    "    if data_type:\n",
    "        df = pd.read_csv(path, index_col=0, dtype=data_type)\n",
    "    else:\n",
    "        df = pd.read_csv(path, index_col=0)\n",
    "    print('Number of rows: {:,}\\n'.format(len(df)))\n",
    "    print('Number of columns: {:,}\\n'.format(len(df.columns)))\n",
    "    \n",
    "    columns_missing_values = df.columns[df.isnull().any()].tolist()\n",
    "    print('{} columns with missing values\\n\\n'.format(len(columns_missing_values)))\n",
    "    \n",
    "    cols = df.columns.tolist()\n",
    "    column_types = [{col: df.dtypes[col].name} for col in cols][:10]\n",
    "    print('column types:\\n')\n",
    "    print(column_types, '\\n\\n')\n",
    "    print(df.head(2))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# print out summary after each features merge\n",
    "def print_merge_details(df_merge_result, df1_name, df2_name):\n",
    "    print('Joining {} on protein {} yields {:,} rows and {:,} columns'. \\\n",
    "          format(df1_name, df2_name, len(df_merge_result), \n",
    "          len(df_merge_result.columns)))\n",
    "\n",
    "\n",
    "# Get the individual feature sets as data frames\n",
    "def load_feature_files():\n",
    "    print('===============================================')\n",
    "    print('\\ndragon_features.csv')\n",
    "    print('===============================================')\n",
    "    # note need to set the data_type to object because it complains, otherwise that the types vary.\n",
    "    df_dragon_features = load_data(data_loc+'drug_features/dragon_features.csv', data_type=object)\n",
    "    \n",
    "    # rename the dragon features since there are duplicate column names in the protein binding-sites data.\n",
    "    df_dragon_features.columns = ['cid_'+col for col in df_dragon_features.columns]\n",
    "    \n",
    "    # handle na values in dragon_features\n",
    "    # Many cells contain \"na\" values. Find the columns that contain 2% or \n",
    "    # less of these values and retain them, throwing away the rest. \n",
    "    # Then mean-impute the \"na\" values in the remaining columns.\n",
    "    pct_threshold = 2\n",
    "    na_threshold = int(91424*pct_threshold/100)\n",
    "    ok_cols = []\n",
    "    for col in df_dragon_features:\n",
    "        na_count = df_dragon_features[col].value_counts().get('na')\n",
    "        if (na_count or 0) <= na_threshold:\n",
    "            ok_cols.append(col)\n",
    "\n",
    "    print('number of columns where the frequency of \"na\" values is <= {}%: {}.'.format(pct_threshold, len(ok_cols)))\n",
    "    \n",
    "    df_dragon_features = df_dragon_features[ok_cols].copy()\n",
    "\n",
    "    # convert all values except \"na\"s to numbers and set \"na\" values to NaNs.\n",
    "    df_dragon_features = df_dragon_features.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    columns_missing_values = df_dragon_features.columns[df_dragon_features.isnull().any()].tolist()\n",
    "    print('{} columns with missing values.\\n\\n'.format(len(columns_missing_values)))\n",
    "\n",
    "    # replace NaNs with column means\n",
    "    df_dragon_features.fillna(df_dragon_features.mean(), inplace=True)\n",
    "\n",
    "    columns_missing_values = df_dragon_features.columns[df_dragon_features.isnull().any()].tolist()\n",
    "    print('{} columns with missing values (after imputing): {}\\n\\n'.format(len(columns_missing_values), \n",
    "                                                                       columns_missing_values))\n",
    "    print('===============================================')\n",
    "    print('reduced_fingerprints_v1.5.csv')\n",
    "    print('===============================================')\n",
    "    df_fingerprints = load_data(data_loc+'drug_features/reduced_fingerprints_v1.5.csv')\n",
    "    \n",
    "    print('===============================================')\n",
    "    print('reduced_binding_site_features_v2.0.csv')\n",
    "    print('===============================================')\n",
    "    df_binding_sites = load_data(data_loc+'protein_features/binding_site_features_v2.csv')\n",
    "    \n",
    "    # Name the index to 'pid' to allow joining to other feaure files later.\n",
    "    df_binding_sites.index.name = 'pid'\n",
    "    \n",
    "    print('===============================================')\n",
    "    print('expasy.csv')\n",
    "    print('===============================================')\n",
    "    df_expasy = load_data(data_loc+'protein_features/expasy.csv')\n",
    "    \n",
    "    print('===============================================')\n",
    "    print('profeat.csv')\n",
    "    print('===============================================')\n",
    "    df_profeat = load_data(data_loc+'protein_features/profeat.csv')\n",
    "    \n",
    "    # Name the index to 'pid' to allow joining to other feaure files later.\n",
    "    df_profeat.index.name = 'pid'\n",
    "    \n",
    "    # profeat has some missing values.\n",
    "    s = df_profeat.isnull().sum(axis = 0)\n",
    "\n",
    "    print('number of missing values for each column containing them is: {}'.format(len(s[s > 0])))\n",
    "\n",
    "    # Drop the rows that have missing values.\n",
    "    df_profeat.dropna(inplace=True)\n",
    "    print('number of rows remaining, without NaNs: {:,}'.format(len(df_profeat)))\n",
    "    \n",
    "    return {'df_dragon_features': df_dragon_features,\n",
    "           'df_fingerprints': df_fingerprints,\n",
    "           'df_binding_sites': df_binding_sites,\n",
    "           'df_expasy': df_expasy,\n",
    "           'df_profeat': df_profeat}\n",
    "    \n",
    "\n",
    "    \n",
    "def create_features(split_file_name, out_file_name, feature_sets):\n",
    "    print('===============================================')\n",
    "    print('interactions.csv')\n",
    "    print('===============================================')\n",
    "    \n",
    "    # load interactions.csv\n",
    "    df_interactions = load_data(interactions_data_loc+split_file_name)\n",
    "\n",
    "    # Rename the 'canonical_cid' column simply to 'cid' to simplifiy joining to the other feature sets later.\n",
    "    df_interactions.rename(columns={\"canonical_cid\": \"cid\"}, inplace=True)\n",
    "    print(df_interactions.head())\n",
    "    \n",
    "    # Get the individual feature sets\n",
    "    df_dragon_features = feature_sets['df_dragon_features']\n",
    "    df_fingerprints = feature_sets['df_fingerprints']\n",
    "    df_binding_sites = feature_sets['df_binding_sites']\n",
    "    df_expasy = feature_sets['df_expasy']\n",
    "    df_profeat = feature_sets['df_profeat']\n",
    "    \n",
    "    print('\\n\\n===============================================')\n",
    "    print('Join the data using {}\\n'.format(split_file_name))\n",
    "    print('===============================================')\n",
    "    \n",
    "    # Form the complete feature set by joining the data frames according to _cid_ and _pid_.\n",
    "    # See the data readme in the Gitbug repository:\n",
    "    # https://github.com/BrianDavisMath/FDA-COVID19/tree/master/data.\n",
    "    \n",
    "    # By convention, the file features should be concatenated in the following order (for consistency):\n",
    "    # **binding_sites**, **expasy**, **profeat**, **dragon_features**, **fingerprints**.\n",
    "    \n",
    "    print('\\n\\n-----------------------------------------------')\n",
    "    print('df_interactions + df_binding_sites = df_features \\n')\n",
    "    df_features = pd.merge(df_interactions, df_binding_sites, on='pid', how='inner')\n",
    "    print_merge_details(df_features, 'interactions', 'binding_sites')\n",
    "    \n",
    "    print('\\n\\n-----------------------------------------------')\n",
    "    print('df_features + df_expasy \\n')\n",
    "    df_features = pd.merge(df_features, df_expasy, on='pid', how='inner')\n",
    "    print_merge_details(df_features, 'features', 'expasy')\n",
    "    \n",
    "    print('\\n\\n-----------------------------------------------')\n",
    "    print('df_features + df_profeat \\n')\n",
    "    df_features = pd.merge(df_features, df_profeat, on='pid', how='inner')\n",
    "    print_merge_details(df_features, 'features', 'df_profeat')\n",
    "    \n",
    "    print('\\n\\n-----------------------------------------------')\n",
    "    print('df_features + df_dragon_features \\n')\n",
    "    df_dragon_features.index.name = 'cid'\n",
    "    df_features = pd.merge(df_features, df_dragon_features, on='cid', how='inner')\n",
    "    print_merge_details(df_features, 'features', 'df_dragon_features')\n",
    "    \n",
    "    print('\\n\\n-----------------------------------------------')\n",
    "    print('df_features + df_fingerprints \\n')\n",
    "    df_features = pd.merge(df_features, df_fingerprints, on='cid', how='inner')\n",
    "    print_merge_details(df_features, 'features', 'df_fingerprints')\n",
    "    \n",
    "    print('\\n\\n-----------------------------------------------')\n",
    "    print('Number of rows in joined feature set: {:,}\\n'.format(len(df_features)))\n",
    "    print('Number of columns in joined feature set: {:,}\\n'.format(len(df_features.columns)))\n",
    "    \n",
    "    # release memory used by previous dataframes.\n",
    "    del df_interactions\n",
    "    del df_binding_sites\n",
    "    del df_expasy\n",
    "    del df_profeat\n",
    "    del df_dragon_features\n",
    "    del df_fingerprints\n",
    "    \n",
    "    # Save features to file\n",
    "    store = pd.HDFStore(data_loc + out_file_name)\n",
    "    store['df'] = df_features\n",
    "    store.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the feature files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "\n",
      "dragon_features.csv\n",
      "===============================================\n",
      "Number of rows: 88,105\n",
      "\n",
      "Number of columns: 3,839\n",
      "\n",
      "0 columns with missing values\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'MW': 'object'}, {'AMW': 'object'}, {'Sv': 'object'}, {'Se': 'object'}, {'Sp': 'object'}, {'Si': 'object'}, {'Mv': 'object'}, {'Me': 'object'}, {'Mp': 'object'}, {'Mi': 'object'}] \n",
      "\n",
      "\n",
      "              MW                AMW      Sv                  Se  \\\n",
      "cid                                                               \n",
      "72792562  474.67  6.781000000000001  41.039              70.101   \n",
      "44394609  546.48              8.674  43.185  63.538000000000004   \n",
      "378422    410.52              7.331  34.740   56.43600000000001   \n",
      "57888919  451.06              6.834  38.685              65.858   \n",
      "54581291  456.58              8.615  36.234               53.52   \n",
      "\n",
      "                          Sp                 Si     Mv                  Me  \\\n",
      "cid                                                                          \n",
      "72792562   43.54600000000001  80.52199999999999  0.586               1.001   \n",
      "44394609  45.233000000000004             69.993  0.685  1.0090000000000001   \n",
      "378422                36.216             63.398  0.620               1.008   \n",
      "57888919              41.631             74.837  0.586               0.998   \n",
      "54581291              37.716             59.607  0.684                1.01   \n",
      "\n",
      "                          Mp                  Mi  ... Psychotic-80  \\\n",
      "cid                                               ...                \n",
      "72792562               0.622                1.15  ...            0   \n",
      "44394609               0.718               1.111  ...            0   \n",
      "378422                 0.647  1.1320000000000001  ...            0   \n",
      "57888919               0.631  1.1340000000000001  ...            0   \n",
      "54581291  0.7120000000000001               1.125  ...            1   \n",
      "\n",
      "         Psychotic-50 Hypertens-80 Hypertens-50 Hypnotic-80 Hypnotic-50  \\\n",
      "cid                                                                       \n",
      "72792562            0            0            0           0           0   \n",
      "44394609            0            0            0           0           0   \n",
      "378422              0            1            0           0           0   \n",
      "57888919            0            1            0           0           0   \n",
      "54581291            0            0            0           0           0   \n",
      "\n",
      "         Neoplastic-80 Neoplastic-50 Infective-80 Infective-50  \n",
      "cid                                                             \n",
      "72792562             0             0            0            0  \n",
      "44394609             0             0            0            0  \n",
      "378422               1             0            1            0  \n",
      "57888919             0             0            0            0  \n",
      "54581291             0             0            0            0  \n",
      "\n",
      "[5 rows x 3839 columns]\n",
      "number of columns where the frequency of \"na\" values is <= 2%: 3640.\n",
      "3565 columns with missing values.\n",
      "\n",
      "\n",
      "0 columns with missing values (after imputing): []\n",
      "\n",
      "\n",
      "===============================================\n",
      "\n",
      "reduced_fingerprints_v1.5.csv\n",
      "===============================================\n",
      "Number of rows: 91,756\n",
      "\n",
      "Number of columns: 2,850\n",
      "\n",
      "0 columns with missing values\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'1': 'int64'}, {'5': 'int64'}, {'6': 'int64'}, {'7': 'int64'}, {'8': 'int64'}, {'11': 'int64'}, {'13': 'int64'}, {'14': 'int64'}, {'15': 'int64'}, {'18': 'int64'}] \n",
      "\n",
      "\n",
      "          1  5  6  7  8  11  13  14  15  18  ...  424_2085  \\\n",
      "cid                                          ...             \n",
      "38258     0  0  0  0  0   0   0   0   0   0  ...         0   \n",
      "23644997  0  0  0  1  0   0   0   0   0   0  ...         0   \n",
      "76314488  1  0  0  0  0   0   1   0   0   0  ...         1   \n",
      "46225960  0  0  0  0  0   0   0   0   0   0  ...         0   \n",
      "3005573   0  0  0  0  0   0   1   0   0   0  ...         0   \n",
      "\n",
      "          3902_2141_1081_1362  1628_3117  2216_3406  1771_585  1540_315_2638  \\\n",
      "cid                                                                            \n",
      "38258                       0          0          0         0              0   \n",
      "23644997                    0          0          0         0              0   \n",
      "76314488                    0          0          0         0              0   \n",
      "46225960                    0          0          0         0              0   \n",
      "3005573                     0          0          0         0              0   \n",
      "\n",
      "          3574_2159  2896_1320_2357  213_2326  4078_192  \n",
      "cid                                                      \n",
      "38258             0               0         0         0  \n",
      "23644997          0               0         0         0  \n",
      "76314488          0               0         0         1  \n",
      "46225960          0               1         0         0  \n",
      "3005573           0               0         0         0  \n",
      "\n",
      "[5 rows x 2850 columns]\n",
      "===============================================\n",
      "educed_binding_site_features_v1.5.csv\n",
      "===============================================\n",
      "Number of rows: 4,189\n",
      "\n",
      "Number of columns: 5,236\n",
      "\n",
      "0 columns with missing values\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'AAU': 'float64'}, {'TCW': 'float64'}, {'WDX': 'float64'}, {'KEX': 'float64'}, {'RIX': 'float64'}, {'CQU': 'float64'}, {'FRX': 'float64'}, {'DSX': 'float64'}, {'SVX': 'float64'}, {'VXR': 'float64'}] \n",
      "\n",
      "\n",
      "        AAU  TCW  WDX  KEX  RIX  CQU  FRX  DSX  SVX  VXR  ...  SYY  PYY_CYY  \\\n",
      "Q9BZP6 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0     -1.0   \n",
      "O00459 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0     -1.0   \n",
      "P0A9A6 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0     -1.0   \n",
      "Q9NR82 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0     -1.0   \n",
      "Q2M2I8 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ... -1.0     -1.0   \n",
      "\n",
      "        AYY_DYY  NYY_EYY  IYY_FYY  HYY_GYY  KYY_LYY  TYY_RYY  YYY_VYY  QYY_WYY  \n",
      "Q9BZP6     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0  \n",
      "O00459     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0  \n",
      "P0A9A6     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0  \n",
      "Q9NR82     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0  \n",
      "Q2M2I8     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0  \n",
      "\n",
      "[5 rows x 5236 columns]\n",
      "===============================================\n",
      "\n",
      "expasy.csv\n",
      "===============================================\n",
      "Number of rows: 4,201\n",
      "\n",
      "Number of columns: 7\n",
      "\n",
      "0 columns with missing values\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'helical': 'float64'}, {'beta': 'float64'}, {'coil': 'float64'}, {'veryBuried': 'float64'}, {'veryExposed': 'float64'}, {'someBuried': 'float64'}, {'someExposed': 'float64'}] \n",
      "\n",
      "\n",
      "        helical   beta   coil  veryBuried  veryExposed  someBuried  \\\n",
      "pid                                                                  \n",
      "10GS_A    0.536  0.096  0.368       0.292        0.254       0.234   \n",
      "1A2C_H    0.089  0.378  0.533       0.313        0.301       0.212   \n",
      "1A30_A    0.091  0.475  0.434       0.192        0.354       0.273   \n",
      "1A42_A    0.143  0.313  0.544       0.286        0.263       0.224   \n",
      "1A4G_A    0.000  0.428  0.572       0.387        0.192       0.277   \n",
      "\n",
      "        someExposed  \n",
      "pid                  \n",
      "10GS_A        0.220  \n",
      "1A2C_H        0.174  \n",
      "1A30_A        0.182  \n",
      "1A42_A        0.228  \n",
      "1A4G_A        0.144  \n",
      "===============================================\n",
      "\n",
      "profeat.csv\n",
      "===============================================\n",
      "Number of rows: 4,167\n",
      "\n",
      "Number of columns: 849\n",
      "\n",
      "80 columns with missing values\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'[G1.1.1.1]': 'float64'}, {'[G1.1.1.2]': 'float64'}, {'[G1.1.1.3]': 'float64'}, {'[G1.1.1.4]': 'float64'}, {'[G1.1.1.5]': 'float64'}, {'[G1.1.1.6]': 'float64'}, {'[G1.1.1.7]': 'float64'}, {'[G1.1.1.8]': 'float64'}, {'[G1.1.1.9]': 'float64'}, {'[G1.1.1.10]': 'float64'}] \n",
      "\n",
      "\n",
      "        [G1.1.1.1]  [G1.1.1.2]  [G1.1.1.3]  [G1.1.1.4]  [G1.1.1.5]  \\\n",
      "10GS_A    7.177033    1.913876    6.220096    4.784689    3.349282   \n",
      "1A2C_H    4.633205    2.702703    6.177606    5.791506    3.474903   \n",
      "1A30_A    3.030303    2.020202    4.040404    4.040404    2.020202   \n",
      "1A42_A    5.019305    0.386100    7.335907    5.019305    4.633205   \n",
      "1A4G_A    6.666667    4.358974    5.641026    6.410256    3.076923   \n",
      "\n",
      "        [G1.1.1.6]  [G1.1.1.7]  [G1.1.1.8]  [G1.1.1.9]  [G1.1.1.10]  ...  \\\n",
      "10GS_A    8.612440    0.956938    3.349282    5.741627    15.311005  ...   \n",
      "1A2C_H    8.494208    1.930502    6.177606    7.335907     7.722008  ...   \n",
      "1A30_A   13.131313    1.010101   15.151515    7.070707    10.101010  ...   \n",
      "1A42_A    8.494208    4.633205    3.474903    9.266409    10.038610  ...   \n",
      "1A4G_A   10.256410    3.076923    6.923077    6.153846     5.384615  ...   \n",
      "\n",
      "        [G7.1.1.71]  [G7.1.1.72]  [G7.1.1.73]  [G7.1.1.74]  [G7.1.1.75]  \\\n",
      "10GS_A    -0.001570     0.002455     0.001529     0.007086     0.001563   \n",
      "1A2C_H    -0.003062    -0.005141     0.003201     0.003635    -0.004960   \n",
      "1A30_A     0.004570     0.004954     0.009780     0.010499    -0.006204   \n",
      "1A42_A     0.003225    -0.000328     0.000452     0.001144     0.000961   \n",
      "1A4G_A    -0.000034     0.001908    -0.002145    -0.001665     0.000629   \n",
      "\n",
      "        [G7.1.1.76]  [G7.1.1.77]  [G7.1.1.78]  [G7.1.1.79]  [G7.1.1.80]  \n",
      "10GS_A     0.001808    -0.003158    -0.003736     0.005282     0.004062  \n",
      "1A2C_H    -0.005522     0.005161     0.001182     0.007673     0.003012  \n",
      "1A30_A    -0.000562    -0.005154     0.002587     0.004035     0.002689  \n",
      "1A42_A    -0.001486    -0.004869    -0.004600     0.000062    -0.002881  \n",
      "1A4G_A    -0.000161     0.004026    -0.000031     0.003000     0.000084  \n",
      "\n",
      "[5 rows x 849 columns]\n",
      "number of missing values for each column containing them is: 80\n",
      "number of rows remaining, without NaNs: 4,161\n"
     ]
    }
   ],
   "source": [
    "# Get the individual feature sets\n",
    "feature_sets = load_feature_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "interactions.csv\n",
      "===============================================\n",
      "Number of rows: 168,765\n",
      "\n",
      "Number of columns: 6\n",
      "\n",
      "0 columns with missing values\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'index': 'int64'}, {'cid': 'int64'}, {'pid': 'object'}, {'activity': 'int64'}, {'sample_activity_score': 'float64'}, {'expanding_mean': 'float64'}] \n",
      "\n",
      "\n",
      "    index       cid     pid  activity  sample_activity_score  expanding_mean\n",
      "0  185362    204106  Q9UP65         1                    1.0        1.000000\n",
      "1  159478  46938678  O15528         0                    1.0        0.500000\n",
      "2  159479  46938678  O15528         1                    1.0        0.666667\n",
      "3  150238  13703975  P22459         0                    1.0        0.500000\n",
      "4  150239  13088125  P22459         0                    1.0        0.400000\n",
      "    index       cid     pid  activity  sample_activity_score  expanding_mean\n",
      "0  185362    204106  Q9UP65         1                    1.0        1.000000\n",
      "1  159478  46938678  O15528         0                    1.0        0.500000\n",
      "2  159479  46938678  O15528         1                    1.0        0.666667\n",
      "3  150238  13703975  P22459         0                    1.0        0.500000\n",
      "4  150239  13088125  P22459         0                    1.0        0.400000\n",
      "\n",
      "\n",
      "===============================================\n",
      "Join the data \n",
      "\n",
      "\n",
      "\n",
      "===============================================\n",
      "df_interactions + df_binding_sites = df_features \n",
      "\n",
      "Joining interactions on protein binding_sites yields 167,702 rows and 8,487 columns\n",
      "\n",
      "\n",
      "===============================================\n",
      "df_features + df_expasy \n",
      "\n",
      "Joining features on protein expasy yields 167,549 rows and 8,494 columns\n",
      "\n",
      "\n",
      "===============================================\n",
      "df_features + df_profeat \n",
      "\n",
      "Joining features on protein df_profeat yields 164,587 rows and 9,343 columns\n",
      "\n",
      "\n",
      "===============================================\n",
      "df_features + df_dragon_features \n",
      "\n",
      "Joining features on protein df_dragon_features yields 164,217 rows and 12,983 columns\n",
      "\n",
      "\n",
      "===============================================\n",
      "df_features + df_fingerprints \n",
      "\n",
      "Joining features on protein df_fingerprints yields 164,217 rows and 17,079 columns\n",
      "\n",
      "\n",
      "===============================================\n",
      "0 columns with missing values: []\n",
      "\n",
      "\n",
      "(164217, 17079)\n",
      "    index       cid     pid  activity  sample_activity_score  expanding_mean  \\\n",
      "0  185362    204106  Q9UP65         1               1.000000        1.000000   \n",
      "1  121666    204106  P47712         0               0.582192        0.696174   \n",
      "2  185357  10290302  Q9UP65         1               0.750000        0.779175   \n",
      "3  166025  10290302  P00403         1               0.750000        0.779064   \n",
      "4  132036  10290302  P00395         1               0.472222        0.545545   \n",
      "\n",
      "   AEK  VEL  EKF  LGM  ...  4086  4087  4088  4089  4090  4091  4092  4093  \\\n",
      "0 -1.0 -1.0 -1.0 -1.0  ...     0     0     0     0     0     0     0     0   \n",
      "1 -1.0 -1.0 -1.0 -1.0  ...     0     0     0     0     0     0     0     0   \n",
      "2 -1.0 -1.0 -1.0 -1.0  ...     0     0     0     0     0     0     0     0   \n",
      "3 -1.0 -1.0 -1.0 -1.0  ...     0     0     0     0     0     0     0     0   \n",
      "4 -1.0 -1.0 -1.0 -1.0  ...     0     0     0     0     0     0     0     0   \n",
      "\n",
      "   4094  4095  \n",
      "0     0     0  \n",
      "1     0     0  \n",
      "2     0     0  \n",
      "3     0     0  \n",
      "4     0     0  \n",
      "\n",
      "[5 rows x 17079 columns]\n",
      "\n",
      "\n",
      "interactions.csv\n",
      "===============================================\n",
      "Number of rows: 19,650\n",
      "\n",
      "Number of columns: 6\n",
      "\n",
      "0 columns with missing values\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'index': 'int64'}, {'cid': 'int64'}, {'pid': 'object'}, {'activity': 'int64'}, {'sample_activity_score': 'float64'}, {'expanding_mean': 'float64'}] \n",
      "\n",
      "\n",
      "         index       cid     pid  activity  sample_activity_score  \\\n",
      "97250    83257  71283192  P16234         0               0.081395   \n",
      "73264   105825   6324668  Q99250         0               0.155612   \n",
      "100410   87896  16038120  O75385         0               0.074074   \n",
      "10246     7845      2170  Q05DJ8         0               0.527778   \n",
      "28855    60931      3823  P11712         1               0.376694   \n",
      "\n",
      "        expanding_mean  \n",
      "97250         0.264049  \n",
      "73264         0.307132  \n",
      "100410        0.257870  \n",
      "10246         0.637065  \n",
      "28855         0.445315  \n",
      "         index       cid     pid  activity  sample_activity_score  \\\n",
      "97250    83257  71283192  P16234         0               0.081395   \n",
      "73264   105825   6324668  Q99250         0               0.155612   \n",
      "100410   87896  16038120  O75385         0               0.074074   \n",
      "10246     7845      2170  Q05DJ8         0               0.527778   \n",
      "28855    60931      3823  P11712         1               0.376694   \n",
      "\n",
      "        expanding_mean  \n",
      "97250         0.264049  \n",
      "73264         0.307132  \n",
      "100410        0.257870  \n",
      "10246         0.637065  \n",
      "28855         0.445315  \n",
      "\n",
      "\n",
      "===============================================\n",
      "Join the data \n",
      "\n",
      "\n",
      "\n",
      "===============================================\n",
      "df_interactions + df_binding_sites = df_features \n",
      "\n",
      "Joining interactions on protein binding_sites yields 19,533 rows and 8,487 columns\n",
      "\n",
      "\n",
      "===============================================\n",
      "df_features + df_expasy \n",
      "\n",
      "Joining features on protein expasy yields 19,488 rows and 8,494 columns\n",
      "\n",
      "\n",
      "===============================================\n",
      "df_features + df_profeat \n",
      "\n",
      "Joining features on protein df_profeat yields 18,975 rows and 9,343 columns\n",
      "\n",
      "\n",
      "===============================================\n",
      "df_features + df_dragon_features \n",
      "\n",
      "Joining features on protein df_dragon_features yields 18,949 rows and 12,983 columns\n",
      "\n",
      "\n",
      "===============================================\n",
      "df_features + df_fingerprints \n",
      "\n",
      "Joining features on protein df_fingerprints yields 18,949 rows and 17,079 columns\n",
      "\n",
      "\n",
      "===============================================\n",
      "0 columns with missing values: []\n",
      "\n",
      "\n",
      "(18949, 17079)\n",
      "   index       cid     pid  activity  sample_activity_score  expanding_mean  \\\n",
      "0  83257  71283192  P16234         0               0.081395        0.264049   \n",
      "1  83256  11723086  P16234         0               0.081395        0.263989   \n",
      "2  83197  11517980  P16234         0               0.081395        0.264070   \n",
      "3  83201  54760053  P16234         0               0.081395        0.264133   \n",
      "4  83254  68783839  P16234         0               0.081395        0.263984   \n",
      "\n",
      "   AEK  VEL  EKF       LGM  ...  4086  4087  4088  4089  4090  4091  4092  \\\n",
      "0 -1.0 -1.0 -1.0  4.173258  ...     0     0     0     0     0     0     0   \n",
      "1 -1.0 -1.0 -1.0  4.173258  ...     0     0     0     0     0     0     0   \n",
      "2 -1.0 -1.0 -1.0  4.173258  ...     0     0     0     1     0     0     0   \n",
      "3 -1.0 -1.0 -1.0  4.173258  ...     0     0     0     0     0     0     0   \n",
      "4 -1.0 -1.0 -1.0  4.173258  ...     0     0     0     0     0     0     0   \n",
      "\n",
      "   4093  4094  4095  \n",
      "0     0     0     0  \n",
      "1     0     0     0  \n",
      "2     0     0     1  \n",
      "3     0     0     0  \n",
      "4     0     0     0  \n",
      "\n",
      "[5 rows x 17079 columns]\n"
     ]
    }
   ],
   "source": [
    "create_features('training_interactions_v2.csv', 'training_features.h5', feature_sets)\n",
    "create_features('validation_interactions_v2.csv', 'validation_features.h5', feature_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
