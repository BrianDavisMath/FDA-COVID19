{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation\n",
    "<hr>\n",
    "\n",
    "This notebook takes the protein and drug files, cleans them and stitches them together into single feature set.\n",
    "\n",
    "It assumes the data is in a sub-directory of the **/data** folder. I've already added entries to the _.gitignore_ file so that they won't be committed to the repository. Note that this file should be updated for new versions of the data.\n",
    "\n",
    "See the [data readme in the Gitbug repository](https://github.com/BrianDavisMath/FDA-COVID19/tree/master/data) for more details.\n",
    "\n",
    "The output is a file called **features.csv**\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(25000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 25 seconds\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%autosave 25\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data location\n",
    "\n",
    "Change this when you get a new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = '../data/FDA-COVID19_files_v1.0/'\n",
    "interactions_data_loc = '../data/training_validation_split/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, data_type=None):\n",
    "    if data_type:\n",
    "        df = pd.read_csv(path, index_col=0, dtype=data_type)\n",
    "    else:\n",
    "        df = pd.read_csv(path, index_col=0)\n",
    "    print('Number of rows: {:,}\\n'.format(len(df)))\n",
    "    print('Number of columns: {:,}\\n'.format(len(df.columns)))\n",
    "    \n",
    "    columns_missing_values = df.columns[df.isnull().any()].tolist()\n",
    "    print('{} columns with missing values\\n\\n'.format(len(columns_missing_values)))\n",
    "    \n",
    "    cols = df.columns.tolist()\n",
    "    column_types = [{col: df.dtypes[col].name} for col in cols][:10]\n",
    "    print('column types:\\n')\n",
    "    print(column_types, '\\n\\n')\n",
    "    \n",
    "    print(df.head())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:17pt; color:darkblue;\">interactions.csv</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 20,000\n",
      "\n",
      "Number of columns: 4\n",
      "\n",
      "0 columns with missing values\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'cid': 'int64'}, {'pid': 'object'}, {'activity': 'int64'}, {'sample_activity_score': 'float64'}] \n",
      "\n",
      "\n",
      "             cid       pid  activity  sample_activity_score\n",
      "106739      2264    P01106         1               0.134146\n",
      "98502   49803313    P30530         1               0.205915\n",
      "59873       2170  CAA56931         0               0.369108\n",
      "18924       3878    1C3B_A         0               0.244034\n",
      "11376      39765  CAQ07474         0               0.438238\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>pid</th>\n",
       "      <th>activity</th>\n",
       "      <th>sample_activity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106739</th>\n",
       "      <td>2264</td>\n",
       "      <td>P01106</td>\n",
       "      <td>1</td>\n",
       "      <td>0.134146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98502</th>\n",
       "      <td>49803313</td>\n",
       "      <td>P30530</td>\n",
       "      <td>1</td>\n",
       "      <td>0.205915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59873</th>\n",
       "      <td>2170</td>\n",
       "      <td>CAA56931</td>\n",
       "      <td>0</td>\n",
       "      <td>0.369108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18924</th>\n",
       "      <td>3878</td>\n",
       "      <td>1C3B_A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11376</th>\n",
       "      <td>39765</td>\n",
       "      <td>CAQ07474</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cid       pid  activity  sample_activity_score\n",
       "106739      2264    P01106         1               0.134146\n",
       "98502   49803313    P30530         1               0.205915\n",
       "59873       2170  CAA56931         0               0.369108\n",
       "18924       3878    1C3B_A         0               0.244034\n",
       "11376      39765  CAQ07474         0               0.438238"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interactions = load_data(interactions_data_loc+'validation_interactions.csv')\n",
    "\n",
    "# Rename the 'canonical_cid' column simply to 'cid' to simplifiy joining to the other feature sets later.\n",
    "df_interactions.rename(columns={\"canonical_cid\": \"cid\"}, inplace=True)\n",
    "df_interactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:17pt; color:darkblue;\">fda_drug_cids.csv</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 3,269\n",
      "\n",
      "Number of columns: 1\n",
      "\n",
      "0 columns with missing values\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'cid': 'object'}] \n",
      "\n",
      "\n",
      "     cid\n",
      "0  16078\n",
      "1   4020\n",
      "2   4021\n",
      "3  60750\n",
      "4   5988\n"
     ]
    }
   ],
   "source": [
    "df_fda_drug_cids = load_data(data_loc+'fda_drug_cids.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:17pt; color:darkgreen;\">drug_features/</span><span style=\"font-weight:bold; font-size:17pt; color:darkblue;\">dragon_features.csv</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 88,105\n",
      "\n",
      "Number of columns: 3,839\n",
      "\n",
      "0 columns with missing values\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'MW': 'object'}, {'AMW': 'object'}, {'Sv': 'object'}, {'Se': 'object'}, {'Sp': 'object'}, {'Si': 'object'}, {'Mv': 'object'}, {'Me': 'object'}, {'Mp': 'object'}, {'Mi': 'object'}] \n",
      "\n",
      "\n",
      "              MW                AMW      Sv                  Se  \\\n",
      "cid                                                               \n",
      "72792562  474.67  6.781000000000001  41.039              70.101   \n",
      "44394609  546.48              8.674  43.185  63.538000000000004   \n",
      "378422    410.52              7.331  34.740   56.43600000000001   \n",
      "57888919  451.06              6.834  38.685              65.858   \n",
      "54581291  456.58              8.615  36.234               53.52   \n",
      "\n",
      "                          Sp                 Si     Mv                  Me  \\\n",
      "cid                                                                          \n",
      "72792562   43.54600000000001  80.52199999999999  0.586               1.001   \n",
      "44394609  45.233000000000004             69.993  0.685  1.0090000000000001   \n",
      "378422                36.216             63.398  0.620               1.008   \n",
      "57888919              41.631             74.837  0.586               0.998   \n",
      "54581291              37.716             59.607  0.684                1.01   \n",
      "\n",
      "                          Mp                  Mi  ... Psychotic-80  \\\n",
      "cid                                               ...                \n",
      "72792562               0.622                1.15  ...            0   \n",
      "44394609               0.718               1.111  ...            0   \n",
      "378422                 0.647  1.1320000000000001  ...            0   \n",
      "57888919               0.631  1.1340000000000001  ...            0   \n",
      "54581291  0.7120000000000001               1.125  ...            1   \n",
      "\n",
      "         Psychotic-50 Hypertens-80 Hypertens-50 Hypnotic-80 Hypnotic-50  \\\n",
      "cid                                                                       \n",
      "72792562            0            0            0           0           0   \n",
      "44394609            0            0            0           0           0   \n",
      "378422              0            1            0           0           0   \n",
      "57888919            0            1            0           0           0   \n",
      "54581291            0            0            0           0           0   \n",
      "\n",
      "         Neoplastic-80 Neoplastic-50 Infective-80 Infective-50  \n",
      "cid                                                             \n",
      "72792562             0             0            0            0  \n",
      "44394609             0             0            0            0  \n",
      "378422               1             0            1            0  \n",
      "57888919             0             0            0            0  \n",
      "54581291             0             0            0            0  \n",
      "\n",
      "[5 rows x 3839 columns]\n"
     ]
    }
   ],
   "source": [
    "# note need to set the data_type to object because it complains, otherwise that the types vary.\n",
    "df_dragon_features = load_data(data_loc+'drug_features/dragon_features.csv', data_type=object)\n",
    "\n",
    "# rename the dragon features since there are duplicate column names in the protein binding-sites data.\n",
    "df_dragon_features.columns = ['cid_'+col for col in df_dragon_features.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## na values in dragon_features\n",
    "\n",
    "\n",
    "Many cells contain **\"na\"** values. Find the columns that contain 2% or less of these values and retain them, throwing away the rest. Then mean-impute the \"na\" values in the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of columns where the frequency of \"na\" values is <= 2%: 3640.\n"
     ]
    }
   ],
   "source": [
    "pct_threshold = 2\n",
    "na_threshold = int(91424*pct_threshold/100)\n",
    "ok_cols = []\n",
    "for col in df_dragon_features:\n",
    "    na_count = df_dragon_features[col].value_counts().get('na')\n",
    "    if (na_count or 0) <= na_threshold:\n",
    "        ok_cols.append(col)\n",
    "        \n",
    "print('number of columns where the frequency of \"na\" values is <= {}%: {}.'.format(pct_threshold, len(ok_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3565 columns with missing values.\n",
      "\n",
      "\n",
      "0 columns with missing values (after imputing): []\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dragon_features = df_dragon_features[ok_cols].copy()\n",
    "\n",
    "# convert all values except \"na\"s to numbers and set \"na\" values to NaNs.\n",
    "df_dragon_features = df_dragon_features.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "columns_missing_values = df_dragon_features.columns[df_dragon_features.isnull().any()].tolist()\n",
    "print('{} columns with missing values.\\n\\n'.format(len(columns_missing_values)))\n",
    "\n",
    "# replace NaNs with column means\n",
    "df_dragon_features.fillna(df_dragon_features.mean(), inplace=True)\n",
    "\n",
    "columns_missing_values = df_dragon_features.columns[df_dragon_features.isnull().any()].tolist()\n",
    "print('{} columns with missing values (after imputing): {}\\n\\n'.format(len(columns_missing_values), \n",
    "                                                                       columns_missing_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle duplicate cids in dragon_features\n",
    "\n",
    "Later on when we were joining the dragon_features we noticed that the inner join increased the number of rows. This is due to duiplicate cids in the dragon_features set.\n",
    "\n",
    "Here we investigate further and resolve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 rows with duplicate cids.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: cid, dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a temporary cid column from the index.\n",
    "df_dragon_features['cid'] = df_dragon_features.index\n",
    "s = df_dragon_features['cid'].value_counts()\n",
    "dup_cids = s[s > 1]\n",
    "print('There are {:,} rows with duplicate cids.\\n\\n'.format(len(dup_cids)))\n",
    "\n",
    "dup_cids.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the cids where the mean interpoint distance is below a threshold. These are the duplicates that can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "dup_keys = dup_cids.keys().tolist()\n",
    "num_dupes = len(dup_keys)\n",
    "\n",
    "bad_cids = [] # just keep one row for each\n",
    "mean_dist_threshold = 0.000001\n",
    "i = 1\n",
    "for cid in dup_keys:\n",
    "    df = df_dragon_features[df_dragon_features['cid']==cid]\n",
    "    \n",
    "    # turn \"na\"s into zeros\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    mean_dist = pdist(df, metric='euclidean').mean()\n",
    "    if mean_dist <= mean_dist:\n",
    "        bad_cids.append(cid)\n",
    "        \n",
    "    clear_output(wait=True)\n",
    "    display('row {} of {:,} (cid = {}), latest mean dist. = {} across {} entries'.format(i, num_dupes, cid, mean_dist, len(df)))\n",
    "    i = i + 1\n",
    "    \n",
    "    del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(bad_cids) > 0:\n",
    "    print('deduping {} items'.format(len(bad_cids)))\n",
    "    \n",
    "    df_dupes = df_dragon_features[df_dragon_features.cid.isin(bad_cids)]\n",
    "    df_dedupe = df_dragon_features[~df_dragon_features.cid.isin(bad_cids)]\n",
    "    \n",
    "    # re-add the first of each dupe back into the data.\n",
    "    first_dupes = []\n",
    "    for cid in bad_cids:\n",
    "        df_first = df_dupes[df_dupes['cid'] == cid].iloc[0]\n",
    "        first_dupes.append(df_first)\n",
    "        \n",
    "    first_dupes = pd.DataFrame(first_dupes)\n",
    "    df_dedupe = df_dedupe.append(first_dupes)\n",
    "    del first_dupes\n",
    "    \n",
    "    print('Number of rows: {:,}\\n'.format(len(df_dedupe)))\n",
    "    print('Number of columns: {:,}\\n'.format(len(df_dedupe.columns)))\n",
    "    \n",
    "    del df_dupes\n",
    "    df_dedupe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we've deduped properly then there should be only one row for each cid in _bad_cids_. Here we just check the first and leave it at that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(bad_cids) > 0:\n",
    "    assert(len(df_dedupe[df_dedupe['cid'] == bad_cids[0]] == 1))\n",
    "    print('assertion passed')\n",
    "    \n",
    "    # delete temporary cid column\n",
    "    df_dedupe.drop(['cid'],axis=1,inplace=True)\n",
    "    del df_dragon_features\n",
    "    df_dragon_features = df_dedupe\n",
    "\n",
    "    print('Number of rows: {:,}\\n'.format(len(df_dragon_features)))\n",
    "    print('Number of columns: {:,}\\n'.format(len(df_dragon_features.columns)))\n",
    "\n",
    "    df_dragon_features.head()\n",
    "else:\n",
    "    # delete temporary cid column\n",
    "    df_dragon_features.drop(['cid'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:17pt; color:darkgreen;\">drug_features/</span><span style=\"font-weight:bold; font-size:17pt; color:darkblue;\">fingerprints.csv</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 91,756\n",
      "\n",
      "Number of columns: 4,096\n",
      "\n",
      "0 columns with missing values\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'0': 'int64'}, {'1': 'int64'}, {'2': 'int64'}, {'3': 'int64'}, {'4': 'int64'}, {'5': 'int64'}, {'6': 'int64'}, {'7': 'int64'}, {'8': 'int64'}, {'9': 'int64'}] \n",
      "\n",
      "\n",
      "          0  1  2  3  4  5  6  7  8  9  ...  4086  4087  4088  4089  4090  \\\n",
      "cid                                     ...                                 \n",
      "38258     0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
      "23644997  0  0  0  0  0  0  0  1  0  0  ...     0     0     0     0     0   \n",
      "76314488  0  1  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
      "46225960  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
      "3005573   0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
      "\n",
      "          4091  4092  4093  4094  4095  \n",
      "cid                                     \n",
      "38258        0     0     0     0     0  \n",
      "23644997     0     0     0     0     0  \n",
      "76314488     0     0     0     0     1  \n",
      "46225960     0     0     0     0     0  \n",
      "3005573      0     0     0     0     0  \n",
      "\n",
      "[5 rows x 4096 columns]\n"
     ]
    }
   ],
   "source": [
    "df_fingerprints = load_data(data_loc+'drug_features/fingerprints.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:17pt; color:darkgreen;\">protein_features/</span><span style=\"font-weight:bold; font-size:17pt; color:darkblue;\">binding_sites_v1.0.csv</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 4,165\n",
      "\n",
      "Number of columns: 8,481\n",
      "\n",
      "0 columns with missing values\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'AEK': 'float64'}, {'VEL': 'float64'}, {'EKF': 'float64'}, {'LGM': 'float64'}, {'VKN': 'float64'}, {'LKP': 'float64'}, {'NEE': 'float64'}, {'TPN': 'float64'}, {'SRL': 'float64'}, {'KEY': 'float64'}] \n",
      "\n",
      "\n",
      "             AEK       VEL       EKF       LGM       VKN       LKP       NEE  \\\n",
      "pid                                                                            \n",
      "Q9WXS0  3.652353  3.626009  3.545504  4.156362  2.803784  2.811862  2.518908   \n",
      "Q16206  3.133440 -1.000000  4.449457 -1.000000 -1.000000 -1.000000 -1.000000   \n",
      "P37231  1.227430 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000   \n",
      "P05556  2.200393 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000   \n",
      "Q9UGH3  1.930957 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000   \n",
      "\n",
      "             TPN       SRL       KEY  ...  FFV  MRW  YWT  AFF  LYW  *PX  SWH  \\\n",
      "pid                                   ...                                      \n",
      "Q9WXS0  1.682034  2.398797  1.334675  ... -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n",
      "Q16206 -1.000000 -1.000000 -1.000000  ... -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n",
      "P37231 -1.000000 -1.000000 -1.000000  ... -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n",
      "P05556 -1.000000 -1.000000 -1.000000  ... -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n",
      "Q9UGH3 -1.000000 -1.000000 -1.000000  ... -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0   \n",
      "\n",
      "        TWW  FLM  RCV  \n",
      "pid                    \n",
      "Q9WXS0 -1.0 -1.0 -1.0  \n",
      "Q16206 -1.0 -1.0 -1.0  \n",
      "P37231 -1.0 -1.0 -1.0  \n",
      "P05556 -1.0 -1.0 -1.0  \n",
      "Q9UGH3 -1.0 -1.0 -1.0  \n",
      "\n",
      "[5 rows x 8481 columns]\n"
     ]
    }
   ],
   "source": [
    "df_binding_sites = load_data(data_loc+'protein_features/binding_sites_v1.0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:17pt; color:darkgreen;\">protein_features/</span><span style=\"font-weight:bold; font-size:17pt; color:darkblue;\">expasy.csv</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 4,201\n",
      "\n",
      "Number of columns: 7\n",
      "\n",
      "0 columns with missing values\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'helical': 'float64'}, {'beta': 'float64'}, {'coil': 'float64'}, {'veryBuried': 'float64'}, {'veryExposed': 'float64'}, {'someBuried': 'float64'}, {'someExposed': 'float64'}] \n",
      "\n",
      "\n",
      "        helical   beta   coil  veryBuried  veryExposed  someBuried  \\\n",
      "pid                                                                  \n",
      "10GS_A    0.536  0.096  0.368       0.292        0.254       0.234   \n",
      "1A2C_H    0.089  0.378  0.533       0.313        0.301       0.212   \n",
      "1A30_A    0.091  0.475  0.434       0.192        0.354       0.273   \n",
      "1A42_A    0.143  0.313  0.544       0.286        0.263       0.224   \n",
      "1A4G_A    0.000  0.428  0.572       0.387        0.192       0.277   \n",
      "\n",
      "        someExposed  \n",
      "pid                  \n",
      "10GS_A        0.220  \n",
      "1A2C_H        0.174  \n",
      "1A30_A        0.182  \n",
      "1A42_A        0.228  \n",
      "1A4G_A        0.144  \n"
     ]
    }
   ],
   "source": [
    "df_expasy = load_data(data_loc+'protein_features/expasy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:17pt; color:darkgreen;\">protein_features/</span><span style=\"font-weight:bold; font-size:17pt; color:darkblue;\">profeat.csv</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 4,167\n",
      "\n",
      "Number of columns: 849\n",
      "\n",
      "80 columns with missing values\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'[G1.1.1.1]': 'float64'}, {'[G1.1.1.2]': 'float64'}, {'[G1.1.1.3]': 'float64'}, {'[G1.1.1.4]': 'float64'}, {'[G1.1.1.5]': 'float64'}, {'[G1.1.1.6]': 'float64'}, {'[G1.1.1.7]': 'float64'}, {'[G1.1.1.8]': 'float64'}, {'[G1.1.1.9]': 'float64'}, {'[G1.1.1.10]': 'float64'}] \n",
      "\n",
      "\n",
      "        [G1.1.1.1]  [G1.1.1.2]  [G1.1.1.3]  [G1.1.1.4]  [G1.1.1.5]  \\\n",
      "10GS_A    7.177033    1.913876    6.220096    4.784689    3.349282   \n",
      "1A2C_H    4.633205    2.702703    6.177606    5.791506    3.474903   \n",
      "1A30_A    3.030303    2.020202    4.040404    4.040404    2.020202   \n",
      "1A42_A    5.019305    0.386100    7.335907    5.019305    4.633205   \n",
      "1A4G_A    6.666667    4.358974    5.641026    6.410256    3.076923   \n",
      "\n",
      "        [G1.1.1.6]  [G1.1.1.7]  [G1.1.1.8]  [G1.1.1.9]  [G1.1.1.10]  ...  \\\n",
      "10GS_A    8.612440    0.956938    3.349282    5.741627    15.311005  ...   \n",
      "1A2C_H    8.494208    1.930502    6.177606    7.335907     7.722008  ...   \n",
      "1A30_A   13.131313    1.010101   15.151515    7.070707    10.101010  ...   \n",
      "1A42_A    8.494208    4.633205    3.474903    9.266409    10.038610  ...   \n",
      "1A4G_A   10.256410    3.076923    6.923077    6.153846     5.384615  ...   \n",
      "\n",
      "        [G7.1.1.71]  [G7.1.1.72]  [G7.1.1.73]  [G7.1.1.74]  [G7.1.1.75]  \\\n",
      "10GS_A    -0.001570     0.002455     0.001529     0.007086     0.001563   \n",
      "1A2C_H    -0.003062    -0.005141     0.003201     0.003635    -0.004960   \n",
      "1A30_A     0.004570     0.004954     0.009780     0.010499    -0.006204   \n",
      "1A42_A     0.003225    -0.000328     0.000452     0.001144     0.000961   \n",
      "1A4G_A    -0.000034     0.001908    -0.002145    -0.001665     0.000629   \n",
      "\n",
      "        [G7.1.1.76]  [G7.1.1.77]  [G7.1.1.78]  [G7.1.1.79]  [G7.1.1.80]  \n",
      "10GS_A     0.001808    -0.003158    -0.003736     0.005282     0.004062  \n",
      "1A2C_H    -0.005522     0.005161     0.001182     0.007673     0.003012  \n",
      "1A30_A    -0.000562    -0.005154     0.002587     0.004035     0.002689  \n",
      "1A42_A    -0.001486    -0.004869    -0.004600     0.000062    -0.002881  \n",
      "1A4G_A    -0.000161     0.004026    -0.000031     0.003000     0.000084  \n",
      "\n",
      "[5 rows x 849 columns]\n"
     ]
    }
   ],
   "source": [
    "df_profeat = load_data(data_loc+'protein_features/profeat.csv')\n",
    "\n",
    "# Name the index to 'pid' to allow joining to other feaure files later.\n",
    "df_profeat.index.name = 'pid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missing values for each column containing them is: 80\n",
      "number of rows remaining, without NaNs: 4,161\n"
     ]
    }
   ],
   "source": [
    "# profeat has some missing values.\n",
    "s = df_profeat.isnull().sum(axis = 0)\n",
    "\n",
    "print('number of missing values for each column containing them is: {}'.format(len(s[s > 0])))\n",
    "\n",
    "# Drop the rows that have missing values.\n",
    "df_profeat.dropna(inplace=True)\n",
    "print('number of rows remaining, without NaNs: {:,}'.format(len(df_profeat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:17pt; color:darkgreen;\">coronavirus_features/</span><span style=\"font-weight:bold; font-size:17pt; color:darkblue;\">coronavirus_expasy.csv</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 29\n",
      "\n",
      "Number of columns: 88\n",
      "\n",
      "0 columns with missing values\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'length': 'int64'}, {'weight': 'float64'}, {'pI': 'float64'}, {'A Total': 'int64'}, {'A Percent': 'float64'}, {'R Total': 'int64'}, {'R Percent': 'float64'}, {'N Total': 'int64'}, {'N Percent': 'float64'}, {'D Total': 'int64'}] \n",
      "\n",
      "\n",
      "          length     weight    pI  A Total  A Percent  R Total  R Percent  \\\n",
      "pid                                                                         \n",
      "QHD43415    7096  794057.79  6.32      487        6.9      244        3.4   \n",
      "QHD43416    1273  141178.47  6.24       79        6.2       42        3.3   \n",
      "QHD43417     275   31122.94  5.55       13        4.7        6        2.2   \n",
      "QHD43418      75    8365.04  8.57        4        5.3        3        4.0   \n",
      "QHD43419     222   25146.62  9.51       19        8.6       14        6.3   \n",
      "\n",
      "          N Total  N Percent  D Total  ...  chargedTotal  chargedPercent  \\\n",
      "pid                                    ...                                 \n",
      "QHD43415      384        5.4      389  ...          1552           0.219   \n",
      "QHD43416       88        6.9       62  ...           230           0.181   \n",
      "QHD43417        8        2.9       13  ...            49           0.178   \n",
      "QHD43418        5        6.7        1  ...             8           0.107   \n",
      "QHD43419       11        5.0        6  ...            39           0.176   \n",
      "\n",
      "          basicTotal  basicPercent  acidicTotal  acidicPercent  \\\n",
      "pid                                                              \n",
      "QHD43415         823         0.116          729          0.103   \n",
      "QHD43416         120         0.094          110          0.086   \n",
      "QHD43417          25         0.091           24          0.087   \n",
      "QHD43418           5         0.067            3          0.040   \n",
      "QHD43419          26         0.117           13          0.059   \n",
      "\n",
      "          hydrophobicTotal  hydrophobicPercent  hydrophilicTotal  \\\n",
      "pid                                                                \n",
      "QHD43415              3252               0.458              1786   \n",
      "QHD43416               557               0.438               321   \n",
      "QHD43417               137               0.498                52   \n",
      "QHD43418                47               0.627                10   \n",
      "QHD43419               121               0.545                35   \n",
      "\n",
      "          hydrophilicPercent  \n",
      "pid                           \n",
      "QHD43415               0.252  \n",
      "QHD43416               0.252  \n",
      "QHD43417               0.189  \n",
      "QHD43418               0.133  \n",
      "QHD43419               0.158  \n",
      "\n",
      "[5 rows x 88 columns]\n"
     ]
    }
   ],
   "source": [
    "df_coronavirus_expasy = load_data(data_loc+'coronavirus_features/coronavirus_expasy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:17pt; color:darkgreen;\">coronavirus_features/</span><span style=\"font-weight:bold; font-size:17pt; color:darkblue;\">coronavirus_porter.csv</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 30\n",
      "\n",
      "Number of columns: 7\n",
      "\n",
      "0 columns with missing values\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'helical': 'float64'}, {'beta': 'float64'}, {'coil': 'float64'}, {'veryBuried': 'float64'}, {'veryExposed': 'float64'}, {'someBuried': 'float64'}, {'someExposed': 'float64'}] \n",
      "\n",
      "\n",
      "          helical   beta   coil  veryBuried  veryExposed  someBuried  \\\n",
      "pid                                                                    \n",
      "QHD43415    0.339  0.219  0.442       0.295        0.009       0.357   \n",
      "QHD43416    0.245  0.312  0.443       0.436        0.106       0.287   \n",
      "QHD43417    0.345  0.196  0.458       0.473        0.175       0.218   \n",
      "QHD43418    0.653  0.000  0.347       0.040        0.787       0.080   \n",
      "QHD43419    0.383  0.284  0.333       0.279        0.203       0.320   \n",
      "\n",
      "          someExposed  \n",
      "pid                    \n",
      "QHD43415        0.339  \n",
      "QHD43416        0.171  \n",
      "QHD43417        0.135  \n",
      "QHD43418        0.093  \n",
      "QHD43419        0.198  \n"
     ]
    }
   ],
   "source": [
    "df_coronavirus_porter = load_data(data_loc+'coronavirus_features/coronavirus_porter.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:17pt; color:darkgreen;\">coronavirus_features/</span><span style=\"font-weight:bold; font-size:17pt; color:darkblue;\">coronavirus_profeat.csv</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 29\n",
      "\n",
      "Number of columns: 849\n",
      "\n",
      "0 columns with missing values\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'[G1.1.1.1]': 'float64'}, {'[G1.1.1.2]': 'float64'}, {'[G1.1.1.3]': 'float64'}, {'[G1.1.1.4]': 'float64'}, {'[G1.1.1.5]': 'float64'}, {'[G1.1.1.6]': 'float64'}, {'[G1.1.1.7]': 'float64'}, {'[G1.1.1.8]': 'float64'}, {'[G1.1.1.9]': 'float64'}, {'[G1.1.1.10]': 'float64'}] \n",
      "\n",
      "\n",
      "          [G1.1.1.1]  [G1.1.1.2]  [G1.1.1.3]  [G1.1.1.4]  [G1.1.1.5]  \\\n",
      "QHD43415    6.863021    3.184893    5.481962    4.791432    4.918264   \n",
      "QHD43416    6.205813    3.142184    4.870385    3.770621    6.048704   \n",
      "QHD43417    4.727273    2.545455    4.727273    4.000000    5.090909   \n",
      "QHD43418    5.333333    4.000000    1.333333    2.666667    6.666667   \n",
      "QHD43419    8.558559    1.801802    2.702703    3.153153    4.954955   \n",
      "\n",
      "          [G1.1.1.6]  [G1.1.1.7]  [G1.1.1.8]  [G1.1.1.9]  [G1.1.1.10]  ...  \\\n",
      "QHD43415    5.806088    2.043405    4.833709    6.116122     9.413754  ...   \n",
      "QHD43416    6.441477    1.335428    5.970149    4.791830     8.483896  ...   \n",
      "QHD43417    5.090909    2.909091    7.636364    4.000000    10.909091  ...   \n",
      "QHD43418    1.333333    0.000000    4.000000    2.666667    18.666667  ...   \n",
      "QHD43419    6.306306    2.252252    9.009009    3.153153    15.765766  ...   \n",
      "\n",
      "          [G7.1.1.71]  [G7.1.1.72]  [G7.1.1.73]  [G7.1.1.74]  [G7.1.1.75]  \\\n",
      "QHD43415     0.000527     0.000844     0.001346     0.000922     0.000320   \n",
      "QHD43416    -0.000696    -0.000724     0.002304     0.003106     0.000724   \n",
      "QHD43417     0.001989     0.001076    -0.000293     0.001269     0.004673   \n",
      "QHD43418     0.000490     0.004200    -0.001037     0.002456     0.004847   \n",
      "QHD43419     0.004468     0.003642     0.004706     0.005608     0.004701   \n",
      "\n",
      "          [G7.1.1.76]  [G7.1.1.77]  [G7.1.1.78]  [G7.1.1.79]  [G7.1.1.80]  \n",
      "QHD43415     0.000632     0.001052     0.001342     0.000306     0.000374  \n",
      "QHD43416     0.002734    -0.000548     0.000223    -0.004617    -0.003577  \n",
      "QHD43417     0.005930    -0.002706     0.000263     0.003124     0.004706  \n",
      "QHD43418     0.005366     0.002756     0.006903     0.001546     0.000493  \n",
      "QHD43419     0.005750     0.004577     0.006347     0.005715     0.009114  \n",
      "\n",
      "[5 rows x 849 columns]\n"
     ]
    }
   ],
   "source": [
    "df_coronavirus_profeat = load_data(data_loc+'coronavirus_features/coronavirus_profeat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the data\n",
    "\n",
    "Form the complete feature set by joining the data frames according to _cid_ and _pid_.\n",
    "\n",
    "See the [data readme in the Gitbug repository](https://github.com/BrianDavisMath/FDA-COVID19/tree/master/data).\n",
    "\n",
    "<span style=\"font-weight:bold; font-size:12pt; color:darkblue;\">Note:</span> By convention, the file features should be concatenated in the following order (for consistency): **binding_sites**, **expasy**, **profeat**, **dragon_features**, **fingerprints**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Feature Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_example_features = load_data(data_loc+'example_feature_concatenation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let the merging begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_merge_details(df_merge_result, df1_name, df2_name):\n",
    "    print('Joining {} on protein {} yields {:,} rows and {:,} columns'. \\\n",
    "          format(df1_name, df2_name, len(df_features), \n",
    "          len(df_features.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:12pt; color:darkblue;\">df_interactions + df_binding_sites = df_features</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining interactions on protein binding_sites yields 19,864 rows and 8,485 columns\n"
     ]
    }
   ],
   "source": [
    "df_features = pd.merge(df_interactions, df_binding_sites, on='pid', how='inner')\n",
    "print_merge_details(df_features, 'interactions', 'binding_sites')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:12pt; color:darkblue;\">df_features + df_expasy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining features on protein expasy yields 19,811 rows and 8,492 columns\n"
     ]
    }
   ],
   "source": [
    "df_features = pd.merge(df_features, df_expasy, on='pid', how='inner')\n",
    "print_merge_details(df_features, 'features', 'expasy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:12pt; color:darkblue;\">df_features + df_profeat</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining features on protein df_profeat yields 19,247 rows and 9,341 columns\n"
     ]
    }
   ],
   "source": [
    "df_features = pd.merge(df_features, df_profeat, on='pid', how='inner')\n",
    "print_merge_details(df_features, 'features', 'df_profeat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:12pt; color:darkblue;\">df_features + df_dragon_features</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining features on protein df_dragon_features yields 19,240 rows and 12,981 columns\n"
     ]
    }
   ],
   "source": [
    "df_dragon_features.index.name = 'cid'\n",
    "df_features = pd.merge(df_features, df_dragon_features, on='cid', how='inner')\n",
    "print_merge_details(df_features, 'features', 'df_dragon_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold; font-size:12pt; color:darkblue;\">df_features + df_fingerprints</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining features on protein df_fingerprints yields 19,240 rows and 17,077 columns\n"
     ]
    }
   ],
   "source": [
    "df_features = pd.merge(df_features, df_fingerprints, on='cid', how='inner')\n",
    "print_merge_details(df_features, 'features', 'df_fingerprints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 columns with missing values: []\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>pid</th>\n",
       "      <th>activity</th>\n",
       "      <th>sample_activity_score</th>\n",
       "      <th>AEK</th>\n",
       "      <th>VEL</th>\n",
       "      <th>EKF</th>\n",
       "      <th>LGM</th>\n",
       "      <th>VKN</th>\n",
       "      <th>LKP</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2264</td>\n",
       "      <td>P01106</td>\n",
       "      <td>1</td>\n",
       "      <td>0.134146</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1573</td>\n",
       "      <td>P01106</td>\n",
       "      <td>1</td>\n",
       "      <td>0.467480</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1858</td>\n",
       "      <td>P01106</td>\n",
       "      <td>1</td>\n",
       "      <td>0.467480</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1858</td>\n",
       "      <td>4KC3_B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.767068</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1858</td>\n",
       "      <td>P48039</td>\n",
       "      <td>0</td>\n",
       "      <td>0.394309</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17077 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cid     pid  activity  sample_activity_score  AEK  VEL  EKF  LGM  VKN  \\\n",
       "0  2264  P01106         1               0.134146 -1.0 -1.0 -1.0 -1.0 -1.0   \n",
       "1  1573  P01106         1               0.467480 -1.0 -1.0 -1.0 -1.0 -1.0   \n",
       "2  1858  P01106         1               0.467480 -1.0 -1.0 -1.0 -1.0 -1.0   \n",
       "3  1858  4KC3_B         1               0.767068 -1.0 -1.0 -1.0 -1.0 -1.0   \n",
       "4  1858  P48039         0               0.394309 -1.0 -1.0 -1.0 -1.0 -1.0   \n",
       "\n",
       "   LKP  ...  4086  4087  4088  4089  4090  4091  4092  4093  4094  4095  \n",
       "0 -1.0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "1 -1.0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "2 -1.0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "3 -1.0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "4 -1.0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 17077 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Any missing values:\n",
    "columns_missing_values = df_features.columns[df_features.isnull().any()].tolist()\n",
    "\n",
    "print('{} columns with missing values: {}\\n\\n'.format(len(columns_missing_values), columns_missing_values))\n",
    "\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free up some memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release memory used by previous dataframes.\n",
    "del df_interactions\n",
    "del df_binding_sites\n",
    "del df_expasy\n",
    "del df_profeat\n",
    "del df_dragon_features\n",
    "del df_fingerprints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save features to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore(data_loc + 'validation_features.h5')\n",
    "store['df'] = df_features\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
