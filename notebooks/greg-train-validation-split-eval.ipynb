{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval models on train-validation split\n",
    "\n",
    "See [here](https://github.com/BrianDavisMath/FDA-COVID19/tree/master/test_train_split).\n",
    "\n",
    "Use the interactions split in [this zip file](https://github.com/BrianDavisMath/FDA-COVID19/blob/master/test_train_split/training_validation_split.zip) to build and train a model. Evaluate the model using thte validation sett and return the model performance using a weighted F1 score.\n",
    "\n",
    "_\"target metric is f1_score with sample weights computed using the script included in the zip file\"_\n",
    "\n",
    "Weights should be applied in the _sklearn.metrics.f1_score_ function's _sample_weight_ argument. Weights for cid/pid pairs are obtained by running the _get_validation_weights_ function that's included in the [zip file](https://github.com/BrianDavisMath/FDA-COVID19/blob/master/test_train_split/training_validation_split.zip).\n",
    "\n",
    "**Note:** bs_features.csv contains the reduced binding site fingerprints for all examples in training and validation sets. Use of this or the original data is optional.\n",
    "\n",
    "**Note:** The two new interactions file, for training and validation feature sets, include a new column: _sample_activity_score_. This can optionally be used to sub-sample the data. Scores of zero are interactions where both the pid and cid show no variance in activity across entire data set; scores close to 1.0 have balanced activity for both pid and cid. The idea is that interactions with score close to zero might not improve model very much, and so may want to be omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(25000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 25 seconds\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%autosave 25\n",
    "\n",
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = '../data/training_validation_split/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, data_type=None):\n",
    "    if data_type:\n",
    "        df = pd.read_csv(path, index_col=0, dtype=data_type)\n",
    "    else:\n",
    "        df = pd.read_csv(path, index_col=0)\n",
    "    print('Number of rows: {:,}\\n'.format(len(df)))\n",
    "    print('Number of columns: {:,}\\n'.format(len(df.columns)))\n",
    "    \n",
    "    columns_missing_values = df.columns[df.isnull().any()].tolist()\n",
    "    print('{} columns with missing values: {}\\n\\n'.format(len(columns_missing_values), columns_missing_values))\n",
    "    \n",
    "    cols = df.columns.tolist()\n",
    "    column_types = [{col: df.dtypes[col].name} for col in cols]\n",
    "    print('column types:\\n')\n",
    "    print(column_types, '\\n\\n')\n",
    "    \n",
    "    print(df.head())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 168,415\n",
      "\n",
      "Number of columns: 4\n",
      "\n",
      "0 columns with missing values: []\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'cid': 'int64'}, {'pid': 'object'}, {'activity': 'int64'}, {'sample_activity_score': 'float64'}] \n",
      "\n",
      "\n",
      "             cid     pid  activity  sample_activity_score\n",
      "185362    204106  Q9UP65         1                    1.0\n",
      "159478  46938678  O15528         0                    1.0\n",
      "159479  46938678  O15528         1                    1.0\n",
      "150238  13703975  P22459         0                    1.0\n",
      "152040  10202642  P01137         0                    1.0\n"
     ]
    }
   ],
   "source": [
    "df_training_interactions = load_data(data_loc+'training_interactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 20,000\n",
      "\n",
      "Number of columns: 4\n",
      "\n",
      "0 columns with missing values: []\n",
      "\n",
      "\n",
      "column types:\n",
      "\n",
      "[{'cid': 'int64'}, {'pid': 'object'}, {'activity': 'int64'}, {'sample_activity_score': 'float64'}] \n",
      "\n",
      "\n",
      "             cid       pid  activity  sample_activity_score\n",
      "106739      2264    P01106         1               0.134146\n",
      "98502   49803313    P30530         1               0.205915\n",
      "59873       2170  CAA56931         0               0.369108\n",
      "18924       3878    1C3B_A         0               0.244034\n",
      "11376      39765  CAQ07474         0               0.438238\n"
     ]
    }
   ],
   "source": [
    "df_validation_interactions = load_data(data_loc+'validation_interactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set size is 12%.\n"
     ]
    }
   ],
   "source": [
    "print('Validation set size is {:0.0f}%.'.format(len(df_validation_interactions)/len(df_training_interactions)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
