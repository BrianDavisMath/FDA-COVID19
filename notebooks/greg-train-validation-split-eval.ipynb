{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval models on train-validation split\n",
    "\n",
    "See [here](https://github.com/BrianDavisMath/FDA-COVID19/tree/master/test_train_split).\n",
    "\n",
    "Use the interactions split in [this zip file](https://github.com/BrianDavisMath/FDA-COVID19/blob/master/test_train_split/training_validation_split.zip) to build and train a model. Evaluate the model using thte validation sett and return the model performance using a weighted F1 score.\n",
    "\n",
    "_\"target metric is f1_score with sample weights computed using the script included in the zip file\"_\n",
    "\n",
    "Weights should be applied in the _sklearn.metrics.f1_score_ function's _sample_weight_ argument. Weights for cid/pid pairs are obtained by running the _get_validation_weights_ function that's included in the [zip file](https://github.com/BrianDavisMath/FDA-COVID19/blob/master/test_train_split/training_validation_split.zip).\n",
    "\n",
    "**Note:** bs_features.csv contains the reduced binding site fingerprints for all examples in training and validation sets. Use of this or the original data is optional.\n",
    "\n",
    "**Note:** The two new interactions file, for training and validation feature sets, include a new column: _sample_activity_score_. This can optionally be used to sub-sample the data. Scores of zero are interactions where both the pid and cid show no variance in activity across entire data set; scores close to 1.0 have balanced activity for both pid and cid. The idea is that interactions with score close to zero might not improve model very much, and so may want to be omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(25000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 25 seconds\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%autosave 25\n",
    "\n",
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = '../data/training_validation_split/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, data_type=None, nrows=None):\n",
    "    if data_type:\n",
    "        df = pd.read_csv(path, index_col=0, dtype=data_type, nrows=nrows)\n",
    "    else:\n",
    "        df = pd.read_csv(path, index_col=0, nrows=nrows)\n",
    "    print('{}: Number of rows: {:,}\\n'.format(path, len(df)))\n",
    "    print('{}: Number of columns: {:,}\\n'.format(path, len(df.columns)))\n",
    "    \n",
    "    print(df.head(1))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_interactions = load_data(data_loc+'training_interactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation_interactions = load_data(data_loc+'validation_interactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Validation set size is {:0.0f}%.'.format(len(df_validation_interactions)/len(df_training_interactions)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small test data set for use in development of the HPC scripts\n",
    "\n",
    "df_training_interactions = load_data(data_loc+'training_interactions.csv', nrows=1000)\n",
    "df_validation_interactions = load_data(data_loc+'validation_interactions.csv', nrows=100)\n",
    "\n",
    "df_training_interactions.rename(columns={\"canonical_cid\": \"cid\"}, inplace=True)\n",
    "df_validation_interactions.rename(columns={\"canonical_cid\": \"cid\"}, inplace=True)\n",
    "\n",
    "pids = df_training_interactions['pid'].tolist() + df_validation_interactions['pid'].tolist()\n",
    "cids = df_training_interactions['cid'].tolist() + df_validation_interactions['cid'].tolist()\n",
    "\n",
    "# drug features\n",
    "df_dragon_features = load_data('../data/FDA-COVID19_files_v1.0/drug_features/dragon_features.csv', data_type=object)\n",
    "df_fingerprints = load_data('../data/FDA-COVID19_files_v1.0/drug_features/fingerprints.csv')\n",
    "\n",
    "# protein features\n",
    "df_binding_sites = load_data('../data/FDA-COVID19_files_v1.0/protein_features/binding_sites_v1.0.csv')\n",
    "df_expasy = load_data('../data/FDA-COVID19_files_v1.0/protein_features/expasy.csv')\n",
    "df_profeat = load_data('../data/FDA-COVID19_files_v1.0/protein_features/profeat.csv')\n",
    "\n",
    "df_dragon_features.index.name = 'cid'\n",
    "df_fingerprints.index.name = 'cid'\n",
    "df_binding_sites.index.name = 'pid'\n",
    "df_expasy.index.name = 'pid'\n",
    "df_profeat.index.name = 'pid'\n",
    "\n",
    "# rename the dragon features since there are duplicate column names in the protein binding-sites data.\n",
    "df_dragon_features.columns = ['cid_'+col for col in df_dragon_features.columns]\n",
    "\n",
    "max_num_dimensions = 10\n",
    "\n",
    "# only include rows that match the subset of interactions we sampled above\n",
    "df_binding_sites = df_binding_sites[df_binding_sites.index.isin(pids)].iloc[:, :max_num_dimensions]\n",
    "df_expasy = df_expasy[df_expasy.index.isin(pids)].iloc[:, :max_num_dimensions]\n",
    "df_profeat = df_profeat[df_profeat.index.isin(pids)].iloc[:, :max_num_dimensions]\n",
    "\n",
    "df_dragon_features = df_dragon_features[df_dragon_features.index.isin(cids)].iloc[:, :max_num_dimensions]\n",
    "df_fingerprints = df_fingerprints[df_fingerprints.index.isin(cids)].iloc[:, :max_num_dimensions]\n",
    "\n",
    "print(len(df_binding_sites))\n",
    "print(len(df_expasy))\n",
    "print(len(df_profeat))\n",
    "print(len(df_dragon_features))\n",
    "print(len(df_fingerprints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "df_interactions + df_binding_sites = df_features \n",
      "\n",
      "Joining interactions on protein binding_sites yields 970 rows and 14 columns\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "df_features + df_expasy \n",
      "\n",
      "Joining features on protein expasy yields 966 rows and 21 columns\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "df_features + df_profeat \n",
      "\n",
      "Joining features on protein df_profeat yields 965 rows and 31 columns\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "df_features + df_dragon_features \n",
      "\n",
      "Joining features on protein df_dragon_features yields 965 rows and 41 columns\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "df_features + df_fingerprints \n",
      "\n",
      "Joining features on protein df_fingerprints yields 965 rows and 51 columns\n",
      "==========================\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "df_interactions + df_binding_sites = df_features \n",
      "\n",
      "Joining interactions on protein binding_sites yields 100 rows and 14 columns\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "df_features + df_expasy \n",
      "\n",
      "Joining features on protein expasy yields 100 rows and 21 columns\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "df_features + df_profeat \n",
      "\n",
      "Joining features on protein df_profeat yields 98 rows and 31 columns\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "df_features + df_dragon_features \n",
      "\n",
      "Joining features on protein df_dragon_features yields 97 rows and 41 columns\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "df_features + df_fingerprints \n",
      "\n",
      "Joining features on protein df_fingerprints yields 97 rows and 51 columns\n"
     ]
    }
   ],
   "source": [
    "# print out summary after each features merge\n",
    "def print_merge_details(df_merge_result, df1_name, df2_name):\n",
    "    print('Joining {} on protein {} yields {:,} rows and {:,} columns'. \\\n",
    "          format(df1_name, df2_name, len(df_merge_result), \n",
    "          len(df_merge_result.columns)))\n",
    "    \n",
    "def merge(df_interactions):\n",
    "    print('\\n\\n-----------------------------------------------')\n",
    "    print('df_interactions + df_binding_sites = df_features \\n')\n",
    "    df_features = pd.merge(df_interactions, df_binding_sites, on='pid', how='inner')\n",
    "    print_merge_details(df_features, 'interactions', 'binding_sites')\n",
    "\n",
    "    print('\\n\\n-----------------------------------------------')\n",
    "    print('df_features + df_expasy \\n')\n",
    "    df_features = pd.merge(df_features, df_expasy, on='pid', how='inner')\n",
    "    print_merge_details(df_features, 'features', 'expasy')\n",
    "\n",
    "    print('\\n\\n-----------------------------------------------')\n",
    "    print('df_features + df_profeat \\n')\n",
    "    df_features = pd.merge(df_features, df_profeat, on='pid', how='inner')\n",
    "    print_merge_details(df_features, 'features', 'df_profeat')\n",
    "\n",
    "    print('\\n\\n-----------------------------------------------')\n",
    "    print('df_features + df_dragon_features \\n')\n",
    "    df_dragon_features.index.name = 'cid'\n",
    "    df_features = pd.merge(df_features, df_dragon_features, on='cid', how='inner')\n",
    "    print_merge_details(df_features, 'features', 'df_dragon_features')\n",
    "\n",
    "    print('\\n\\n-----------------------------------------------')\n",
    "    print('df_features + df_fingerprints \\n')\n",
    "    df_features = pd.merge(df_features, df_fingerprints, on='cid', how='inner')\n",
    "    print_merge_details(df_features, 'features', 'df_fingerprints')\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "df_training_features = merge(df_training_interactions)\n",
    "print('==========================')\n",
    "df_validation_features = merge(df_validation_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save test features to file\n",
    "print(len(df_binding_sites))\n",
    "print(len(df_expasy))\n",
    "print(len(df_profeat))\n",
    "print(len(df_dragon_features))\n",
    "print(len(df_fingerprints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_interactions.to_csv('../runner/test_data/training_validation_split/training_interactions.csv')\n",
    "df_validation_interactions.to_csv('../runner/test_data/training_validation_split/validation_interactions.csv')\n",
    "\n",
    "df_binding_sites.to_csv('../runner/test_data/protein_features/binding_sites.csv')\n",
    "df_expasy.to_csv('../runner/test_data/protein_features/expasy.csv')\n",
    "df_profeat.to_csv('../runner/test_data/protein_features/profeat.csv')\n",
    "\n",
    "df_dragon_features.to_csv('../runner/test_data/drug_features/dragon_features.csv')\n",
    "df_fingerprints.to_csv('../runner/test_data/drug_features/fingerprints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
