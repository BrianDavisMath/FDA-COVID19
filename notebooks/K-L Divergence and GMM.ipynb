{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kullback-Leibler divergence\n",
    "\n",
    "Use K-L divergence to determine the effect of target variable (activity) values (0 or 1) on a Gaussian mixture model over the data.\n",
    "\n",
    "Apply this only to the continuous features, separately for cid and pid.\n",
    "\n",
    "References:\n",
    "\n",
    "* [KL Divergence Python Example](https://towardsdatascience.com/kl-divergence-python-example-b87069e4b810)—a nice explanation and example\n",
    "* [Stackexchange: Calculating KL Divergence in Python\n",
    "](https://datascience.stackexchange.com/questions/9262/calculating-kl-divergence-in-python)—some good notes on which Python libraries to use\n",
    "* [Mutual Information](https://en.wikipedia.org/wiki/Mutual_information)—seems relevant here\n",
    "* [Sensitivity Analysis in Gaussian Bayesian Networks Using a Divergence Measure](https://www.researchgate.net/publication/233216409_Sensitivity_Analysis_in_Gaussian_Bayesian_Networks_Using_a_Divergence_Measure)\n",
    "* [Clustering with Gaussian Mixture Models](https://pythonmachinelearning.pro/clustering-with-gaussian-mixture-models/)\n",
    "* [scikit-learn Gaussian mixture models](https://scikit-learn.org/stable/modules/mixture.html)\n",
    "* [Approximating the Kullback Leibler Divergence Between Gaussian Mixture Models](https://www.researchgate.net/publication/4249249_Approximating_the_Kullback_Leibler_Divergence_Between_Gaussian_Mixture_Models)\n",
    "* [Stackoverlflow: KL-Divergence of two GMMs\n",
    "](https://stackoverflow.com/questions/26079881/kl-divergence-of-two-gmms)\n",
    "* [Stackexchange: Trying to implement the Jensen-Shannon Divergence for Multivariate Gaussians](https://stats.stackexchange.com/questions/345915/trying-to-implement-the-jensen-shannon-divergence-for-multivariate-gaussians)—related and refering to the above Stackoverflow Q&A\n",
    "* [Stackoverlflow: predict_proba is not working for my gaussian mixture model (sklearn, python)\n",
    "](https://stackoverflow.com/questions/56993070/predict-proba-is-not-working-for-my-gaussian-mixture-model-sklearn-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the features files for CIDs and PIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = '../data/FDA-COVID19_files_v1.0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the individual feature sets as data frames\n",
    "  def __load_feature_files():\n",
    "    print('===============================================')\n",
    "    print('dragon_features.csv')\n",
    "    print('===============================================')\n",
    "    # note need to set the data_type to object because it complains, otherwise that the types vary.\n",
    "    df_dragon_features = __load_data(data_loc+'drug_features/dragon_features.csv', data_type=object)\n",
    "    \n",
    "    # rename the dragon features since there are duplicate column names in the protein binding-sites data.\n",
    "    df_dragon_features.columns = ['cid_'+col for col in df_dragon_features.columns]\n",
    "    \n",
    "    # handle na values in dragon_features\n",
    "    # Many cells contain \"na\" values. Find the columns that contain 2% or \n",
    "    # less of these values and retain them, throwing away the rest. \n",
    "    # Then mean-impute the \"na\" values in the remaining columns.\n",
    "    pct_threshold = 2\n",
    "    na_threshold = int(len(df_dragon_features)*pct_threshold/100)\n",
    "    ok_cols = []\n",
    "\n",
    "    for col in df_dragon_features:\n",
    "        na_count = df_dragon_features[col].value_counts().get('na')\n",
    "        if (na_count or 0) <= na_threshold:\n",
    "            ok_cols.append(col)\n",
    "\n",
    "    print('number of columns where the frequency of \"na\" values is <= {}%: {}.'.format(pct_threshold, len(ok_cols)))\n",
    "    \n",
    "    df_dragon_features = df_dragon_features[ok_cols]\n",
    "\n",
    "    # convert all values except \"na\"s to numbers and set \"na\" values to NaNs.\n",
    "    df_dragon_features = df_dragon_features.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    columns_missing_values = df_dragon_features.columns[df_dragon_features.isnull().any()].tolist()\n",
    "    print('{} columns with missing values.'.format(len(columns_missing_values)))\n",
    "\n",
    "    # replace NaNs with column means\n",
    "    df_dragon_features.fillna(df_dragon_features.mean(), inplace=True)\n",
    "\n",
    "    columns_missing_values = df_dragon_features.columns[df_dragon_features.isnull().any()].tolist()\n",
    "    print('{} columns with missing values (after imputing): {}'.format(len(columns_missing_values), \n",
    "                                                                       columns_missing_values))    \n",
    "    print('===============================================')\n",
    "    print('binding_site_features_v2.csv')\n",
    "    print('===============================================')\n",
    "    df_binding_sites = __load_data(data_loc+'protein_features/binding_site_features_v2.csv')\n",
    "    \n",
    "    # Name the index to 'pid' to allow joining to other feaure files later.\n",
    "    df_binding_sites.index.name = 'pid'\n",
    "    \n",
    "    print('===============================================')\n",
    "    print('expasy.csv')\n",
    "    print('===============================================')\n",
    "    df_expasy = __load_data(data_loc+'protein_features/expasy.csv')\n",
    "    \n",
    "    print('===============================================')\n",
    "    print('profeat.csv')\n",
    "    print('===============================================')\n",
    "    df_profeat = __load_data(data_loc+'protein_features/profeat.csv')\n",
    "    \n",
    "    # Name the index to 'pid' to allow joining to other feaure files later.\n",
    "    df_profeat.index.name = 'pid'\n",
    "    \n",
    "    # profeat has some missing values.\n",
    "    s = df_profeat.isnull().sum(axis = 0)\n",
    "\n",
    "    print('number of missing values for each column containing them is: {}'.format(len(s[s > 0])))\n",
    "\n",
    "    # Drop the rows that have missing values.\n",
    "    df_profeat.dropna(inplace=True)\n",
    "    print('number of rows remaining, without NaNs: {:,}'.format(len(df_profeat)))\n",
    "    \n",
    "    return {'df_dragon_features': df_dragon_features,\n",
    "           'df_binding_sites': df_binding_sites,\n",
    "           'df_expasy': df_expasy,\n",
    "           'df_profeat': df_profeat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a specific features CSV file\n",
    "  def __load_data(path, data_type=None):\n",
    "    if data_type:\n",
    "        df = pd.read_csv(path, index_col=0, dtype=data_type)\n",
    "    else:\n",
    "        df = pd.read_csv(path, index_col=0)\n",
    "    print('Number of rows: {:,}'.format(len(df)))\n",
    "    print('Number of columns: {:,}'.format(len(df.columns)))\n",
    "    \n",
    "    columns_missing_values = df.columns[df.isnull().any()].tolist()\n",
    "    print('{} columns with missing values'.format(len(columns_missing_values)))\n",
    "    \n",
    "    print(df.head(2))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "dragon_features.csv\n",
      "===============================================\n",
      "Number of rows: 88,105\n",
      "Number of columns: 3,839\n",
      "0 columns with missing values\n",
      "              MW                AMW      Sv                  Se  \\\n",
      "cid                                                               \n",
      "72792562  474.67  6.781000000000001  41.039              70.101   \n",
      "44394609  546.48              8.674  43.185  63.538000000000004   \n",
      "\n",
      "                          Sp                 Si     Mv                  Me  \\\n",
      "cid                                                                          \n",
      "72792562   43.54600000000001  80.52199999999999  0.586               1.001   \n",
      "44394609  45.233000000000004             69.993  0.685  1.0090000000000001   \n",
      "\n",
      "             Mp     Mi  ... Psychotic-80 Psychotic-50 Hypertens-80  \\\n",
      "cid                     ...                                          \n",
      "72792562  0.622   1.15  ...            0            0            0   \n",
      "44394609  0.718  1.111  ...            0            0            0   \n",
      "\n",
      "         Hypertens-50 Hypnotic-80 Hypnotic-50 Neoplastic-80 Neoplastic-50  \\\n",
      "cid                                                                         \n",
      "72792562            0           0           0             0             0   \n",
      "44394609            0           0           0             0             0   \n",
      "\n",
      "         Infective-80 Infective-50  \n",
      "cid                                 \n",
      "72792562            0            0  \n",
      "44394609            0            0  \n",
      "\n",
      "[2 rows x 3839 columns]\n",
      "number of columns where the frequency of \"na\" values is <= 2%: 3640.\n",
      "3565 columns with missing values.\n",
      "0 columns with missing values (after imputing): []\n",
      "===============================================\n",
      "binding_site_features_v2.csv\n",
      "===============================================\n",
      "Number of rows: 4,209\n",
      "Number of columns: 5,258\n",
      "0 columns with missing values\n",
      "          TAA    MAA    AAA    SAA    RAA    VAA    LAA    KAA    EAA    QAA  \\\n",
      "Q9BZP6   True  False  False  False  False  False  False  False  False  False   \n",
      "P43003  False  False  False  False  False  False  False  False  False  False   \n",
      "\n",
      "        ...  YYY_VYY  CYY_DYY  AYY_EYY  IYY_FYY  KYY_LYY  HYY_NYY  GYY_PYY  \\\n",
      "Q9BZP6  ...    False    False    False    False    False    False    False   \n",
      "P43003  ...    False    False    False    False    False    False    False   \n",
      "\n",
      "        TYY_RYY  QYY_WYY    AZZ  \n",
      "Q9BZP6    False    False  False  \n",
      "P43003    False    False  False  \n",
      "\n",
      "[2 rows x 5258 columns]\n",
      "===============================================\n",
      "expasy.csv\n",
      "===============================================\n",
      "Number of rows: 4,201\n",
      "Number of columns: 7\n",
      "0 columns with missing values\n",
      "        helical   beta   coil  veryBuried  veryExposed  someBuried  \\\n",
      "pid                                                                  \n",
      "10GS_A    0.536  0.096  0.368       0.292        0.254       0.234   \n",
      "1A2C_H    0.089  0.378  0.533       0.313        0.301       0.212   \n",
      "\n",
      "        someExposed  \n",
      "pid                  \n",
      "10GS_A        0.220  \n",
      "1A2C_H        0.174  \n",
      "===============================================\n",
      "profeat.csv\n",
      "===============================================\n",
      "Number of rows: 4,167\n",
      "Number of columns: 849\n",
      "80 columns with missing values\n",
      "        [G1.1.1.1]  [G1.1.1.2]  [G1.1.1.3]  [G1.1.1.4]  [G1.1.1.5]  \\\n",
      "10GS_A    7.177033    1.913876    6.220096    4.784689    3.349282   \n",
      "1A2C_H    4.633205    2.702703    6.177606    5.791506    3.474903   \n",
      "\n",
      "        [G1.1.1.6]  [G1.1.1.7]  [G1.1.1.8]  [G1.1.1.9]  [G1.1.1.10]  ...  \\\n",
      "10GS_A    8.612440    0.956938    3.349282    5.741627    15.311005  ...   \n",
      "1A2C_H    8.494208    1.930502    6.177606    7.335907     7.722008  ...   \n",
      "\n",
      "        [G7.1.1.71]  [G7.1.1.72]  [G7.1.1.73]  [G7.1.1.74]  [G7.1.1.75]  \\\n",
      "10GS_A    -0.001570     0.002455     0.001529     0.007086     0.001563   \n",
      "1A2C_H    -0.003062    -0.005141     0.003201     0.003635    -0.004960   \n",
      "\n",
      "        [G7.1.1.76]  [G7.1.1.77]  [G7.1.1.78]  [G7.1.1.79]  [G7.1.1.80]  \n",
      "10GS_A     0.001808    -0.003158    -0.003736     0.005282     0.004062  \n",
      "1A2C_H    -0.005522     0.005161     0.001182     0.007673     0.003012  \n",
      "\n",
      "[2 rows x 849 columns]\n",
      "number of missing values for each column containing them is: 80\n",
      "number of rows remaining, without NaNs: 4,161\n"
     ]
    }
   ],
   "source": [
    "feature_sets = __load_feature_files()\n",
    "\n",
    "df_dragon_features = feature_sets['df_dragon_features']\n",
    "df_binding_sites = feature_sets['df_binding_sites']\n",
    "df_expasy = feature_sets['df_expasy']\n",
    "df_profeat = feature_sets['df_profeat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the features for CIDs and PIDs with the interactions.\n",
    "\n",
    "This yields a set of CID features and a set of PID features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 7,972\n",
      "Number of columns: 5\n",
      "0 columns with missing values\n",
      "    cid       pid  activity  cid_binary_weights  pid_binary_weights\n",
      "0   938  AAB59829         1            0.952894            0.996703\n",
      "1  1986  AAB59829         1            0.975912            0.996703\n"
     ]
    }
   ],
   "source": [
    "interactions = '../data/validation_interactions_v5.csv'\n",
    "df_interactions = __load_data(interactions)\n",
    "\n",
    "df_pid = pd.merge(df_interactions, df_expasy, on='pid', how='inner')\n",
    "df_pid = pd.merge(df_pid, df_profeat, on='pid', how='inner')\n",
    "\n",
    "df_cid = pd.merge(df_interactions, df_dragon_features, on='cid', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for types and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7763, 861)\n",
      "(7969, 3645)\n"
     ]
    }
   ],
   "source": [
    "df_pid.activity = df_pid.activity.astype(float)\n",
    "df_cid.activity = df_cid.activity.astype(float)\n",
    "print(df_pid.shape)\n",
    "print(df_cid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Any missing values?\n",
    "print(df_pid.isnull().values.any())\n",
    "print(df_cid.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    859\n",
       "int64        1\n",
       "object       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pid.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    3597\n",
       "int64        47\n",
       "object        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cid.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{dtype('int64'): Index(['cid', 'cid_nAT', 'cid_nSK', 'cid_nTA', 'cid_nBT', 'cid_nBO', 'cid_nBM',\n",
       "        'cid_RBN', 'cid_nDB', 'cid_nTB', 'cid_nAB', 'cid_nH', 'cid_nC',\n",
       "        'cid_nN', 'cid_nO', 'cid_nP', 'cid_nS', 'cid_nF', 'cid_nCL', 'cid_nBR',\n",
       "        'cid_nI', 'cid_nB', 'cid_nHM', 'cid_nHet', 'cid_nX', 'cid_nCsp3',\n",
       "        'cid_nCsp2', 'cid_nCsp', 'cid_nStructures', 'cid_totalcharge',\n",
       "        'cid_nCIC', 'cid_nCIR', 'cid_TRS', 'cid_Rperim', 'cid_Rbrid', 'cid_NRS',\n",
       "        'cid_nR03', 'cid_nR04', 'cid_nR05', 'cid_nR06', 'cid_nR07', 'cid_nR08',\n",
       "        'cid_nR09', 'cid_nR10', 'cid_nR11', 'cid_nR12', 'cid_nBnz'],\n",
       "       dtype='object'),\n",
       " dtype('float64'): Index(['activity', 'cid_binary_weights', 'pid_binary_weights', 'cid_MW',\n",
       "        'cid_AMW', 'cid_Sv', 'cid_Se', 'cid_Sp', 'cid_Si', 'cid_Mv',\n",
       "        ...\n",
       "        'cid_Hy', 'cid_TPSA(NO)', 'cid_TPSA(Tot)', 'cid_SAtot', 'cid_SAacc',\n",
       "        'cid_SAdon', 'cid_Vx', 'cid_VvdwMG', 'cid_VvdwZAZ', 'cid_PDI'],\n",
       "       dtype='object', length=3597),\n",
       " dtype('O'): Index(['pid'], dtype='object')}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cid.columns.to_series().groupby(df_cid.dtypes).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>pid</th>\n",
       "      <th>activity</th>\n",
       "      <th>cid_binary_weights</th>\n",
       "      <th>pid_binary_weights</th>\n",
       "      <th>helical</th>\n",
       "      <th>beta</th>\n",
       "      <th>coil</th>\n",
       "      <th>veryBuried</th>\n",
       "      <th>veryExposed</th>\n",
       "      <th>...</th>\n",
       "      <th>[G7.1.1.71]</th>\n",
       "      <th>[G7.1.1.72]</th>\n",
       "      <th>[G7.1.1.73]</th>\n",
       "      <th>[G7.1.1.74]</th>\n",
       "      <th>[G7.1.1.75]</th>\n",
       "      <th>[G7.1.1.76]</th>\n",
       "      <th>[G7.1.1.77]</th>\n",
       "      <th>[G7.1.1.78]</th>\n",
       "      <th>[G7.1.1.79]</th>\n",
       "      <th>[G7.1.1.80]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>938</td>\n",
       "      <td>AAB59829</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952894</td>\n",
       "      <td>0.996703</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>-0.001869</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.001509</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.002322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986</td>\n",
       "      <td>AAB59829</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975912</td>\n",
       "      <td>0.996703</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>-0.001869</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.001509</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.002322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37542</td>\n",
       "      <td>AAB59829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.963498</td>\n",
       "      <td>0.996703</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>-0.001869</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.001509</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.002322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>445580</td>\n",
       "      <td>AAB59829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.973330</td>\n",
       "      <td>0.996703</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>-0.001869</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.001509</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.002322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4100</td>\n",
       "      <td>AAB59829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.923492</td>\n",
       "      <td>0.996703</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>-0.001869</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.001509</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.002322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 861 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cid       pid  activity  cid_binary_weights  pid_binary_weights  \\\n",
       "0     938  AAB59829       1.0            0.952894            0.996703   \n",
       "1    1986  AAB59829       1.0            0.975912            0.996703   \n",
       "2   37542  AAB59829       0.0            0.963498            0.996703   \n",
       "3  445580  AAB59829       0.0            0.973330            0.996703   \n",
       "4    4100  AAB59829       0.0            0.923492            0.996703   \n",
       "\n",
       "   helical   beta   coil  veryBuried  veryExposed  ...  [G7.1.1.71]  \\\n",
       "0    0.349  0.219  0.432       0.326        0.187  ...     0.003074   \n",
       "1    0.349  0.219  0.432       0.326        0.187  ...     0.003074   \n",
       "2    0.349  0.219  0.432       0.326        0.187  ...     0.003074   \n",
       "3    0.349  0.219  0.432       0.326        0.187  ...     0.003074   \n",
       "4    0.349  0.219  0.432       0.326        0.187  ...     0.003074   \n",
       "\n",
       "   [G7.1.1.72]  [G7.1.1.73]  [G7.1.1.74]  [G7.1.1.75]  [G7.1.1.76]  \\\n",
       "0     0.000574    -0.001384    -0.001869    -0.000164    -0.001509   \n",
       "1     0.000574    -0.001384    -0.001869    -0.000164    -0.001509   \n",
       "2     0.000574    -0.001384    -0.001869    -0.000164    -0.001509   \n",
       "3     0.000574    -0.001384    -0.001869    -0.000164    -0.001509   \n",
       "4     0.000574    -0.001384    -0.001869    -0.000164    -0.001509   \n",
       "\n",
       "   [G7.1.1.77]  [G7.1.1.78]  [G7.1.1.79]  [G7.1.1.80]  \n",
       "0     0.000604    -0.000104     0.001366     0.002322  \n",
       "1     0.000604    -0.000104     0.001366     0.002322  \n",
       "2     0.000604    -0.000104     0.001366     0.002322  \n",
       "3     0.000604    -0.000104     0.001366     0.002322  \n",
       "4     0.000604    -0.000104     0.001366     0.002322  \n",
       "\n",
       "[5 rows x 861 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a GMM over each feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_pid = GaussianMixture(n_components=100,\n",
    "              covariance_type='full', max_iter=20, random_state=42, reg_covar=0.00001)\n",
    "\n",
    "gmm_cid = GaussianMixture(n_components=100,\n",
    "              covariance_type='full', max_iter=10, random_state=42, reg_covar=0.00001)\n",
    "\n",
    "# Drop non-feature cols\n",
    "# Leave activity in there we'll flip that to determine sensistivity\n",
    "pids = df_pid.drop(['cid','pid','cid_binary_weights','pid_binary_weights'], axis=1)\n",
    "cids = df_cid.drop(['cid','pid','cid_binary_weights','pid_binary_weights'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_scaler = MinMaxScaler()\n",
    "pids = pid_scaler.fit_transform(pids)\n",
    "cid_scaler = MinMaxScaler()\n",
    "cids = cid_scaler.fit_transform(cids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_cid.fit(cids)\n",
    "gmm_cid.converged_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_pid.fit(pids)\n",
    "gmm_pid.converged_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobis distance differences when flipping activity\n",
    "\n",
    "For each point, obtain a prediction from GMM of its closest cluster. Then calculate the mahalanobis distance to its  cluster. Next, flip the activity bit and re-predict and calculate distance again. Finally, calculate the poiint's score given the change in distance. NOTE: this assumes that flipping activity does not change cluster membership, only likelihood of membership of the same cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2657779669195013\n",
      "0.30616668439870326\n",
      "3.2657779669195013\n",
      "0.30616668439870326\n",
      "0.30616668439870326\n",
      "3.2657779669195013\n",
      "0.30616668439870326\n",
      "3.2657779669195013\n",
      "0.30616668439870326\n",
      "3.2657779669195013\n",
      "0.30616668439870326\n",
      "3.2657779669195013\n",
      "0.30616668439870326\n",
      "3.2657779669195013\n",
      "0.30616668439870326\n",
      "3.2657779669195013\n",
      "0.30616668439870326\n",
      "3.2657779669195013\n",
      "0.30616668439870326\n",
      "3.2657779669195013\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def dist(model, v):\n",
    "    p = model.predict_proba(v)\n",
    "    cluster = np.argmax(p)\n",
    "    mu = model.means_[cluster]\n",
    "    cov = model.covariances_[cluster]\n",
    "    icov = np.linalg.inv(cov) \n",
    "    return distance.mahalanobis(v, mu, icov)\n",
    "\n",
    "def get_score(vin, model):\n",
    "    v = [vin]\n",
    "    d1 = dist(model, v)\n",
    "    print(d1)\n",
    "\n",
    "    # Flip activity and measure distance\n",
    "    if vin[0] == 1.0:\n",
    "        vin[0] = 0.0\n",
    "    else:\n",
    "        vin[0] = 1.0\n",
    "\n",
    "    d2 = dist(model, v)\n",
    "    print(d2)\n",
    "    \n",
    "    score = 1 - 2 * np.abs(d1-d2)/d1+d2\n",
    "    return score\n",
    "    \n",
    "pid_scores = [get_score(v, gmm_pid) for v in pids[:10]] # Try on the first 10 pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.5063333156012968,\n",
       " -0.5063333156012968,\n",
       " -15.067555366413831,\n",
       " -15.067555366413831,\n",
       " -15.067555366413831,\n",
       " -15.067555366413831,\n",
       " -15.067555366413831,\n",
       " -15.067555366413831,\n",
       " -15.067555366413831,\n",
       " -15.067555366413831]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pid_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each row in each feature set flip the activity and measure the difference in class membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_pid.predict_proba(pid_scaler.transform([pids[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-L divergence\n",
    "\n",
    "Since there is no closed-form solution over GMMs we will use an approximation based upon Monte Carlo simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_kl(gmm_p, gmm_q, n_samples=10**5):\n",
    "    X = gmm_p.sample(n_samples)\n",
    "    log_p_X, _ = gmm_p.score_samples(X)\n",
    "    log_q_X, _ = gmm_q.score_samples(X)\n",
    "    return log_p_X.mean() - log_q_X.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For reference: Brian's code for doing a similiar thing on the binary features using LDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation weighting\n",
    "# train LDA for validation weights\n",
    "validation_interactions = pd.read_csv(validation_interactions_csv, index_col=0)\n",
    "validation_interactions.drop(\"latent_prob_delta_ratio\", axis=1, inplace=True)\n",
    "required_training_interactions = pd.read_csv(required_training_interactions_csv, index_col=0)\n",
    "optional_training_interactions = pd.read_csv(optional_training_interactions_csv, index_col=0)\n",
    "\n",
    "opt_unique = optional_training_interactions.drop_duplicates([\"cid\", \"activity\"]).drop(\"activity_score\", axis=1)\n",
    "req_unique = required_training_interactions.drop_duplicates([\"cid\", \"activity\"])\n",
    "\n",
    "training_unique = pd.concat([opt_unique, req_unique]).drop_duplicates([\"cid\", \"activity\"])\n",
    "num_topics = 100\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, random_state=42, learning_method=\"online\", n_jobs=-1)\n",
    "\n",
    "cid_fingerprints_file = \"dataset_raw_files/fingerprints.csv\"\n",
    "cid_fingerprints = pd.read_csv(cid_fingerprints_file)\n",
    "cid_interactions = cid_fingerprints.merge(training_unique.drop(\"pid\", axis=1), on=\"cid\").drop(\"cid\", axis=1)\n",
    "\n",
    "lda.fit(cid_interactions)\n",
    "del cid_interactions\n",
    "cid_fingerprints[\"pos\"] = 1\n",
    "cid_fingerprints[\"neg\"] = 0\n",
    "cid_fingerprints.set_index(\"cid\", inplace=True)\n",
    "\n",
    "latent_prob_pos = np.max(lda.transform(cid_fingerprints.drop(\"neg\", axis=1)), axis=1)\n",
    "cid_fingerprints[\"latent_prob_neg\"] = np.max(lda.transform(cid_fingerprints.drop(\"pos\", axis=1)), axis=1)\n",
    "cid_fingerprints.reset_index(inplace=True)\n",
    "cid_fingerprints[\"latent_prob_pos\"] = latent_prob_pos\n",
    "cid_fingerprints.drop([\"pos\", \"neg\"], axis=1, inplace=True)\n",
    "cid_fingerprints[\"latent_prob_delta\"] = np.abs(cid_fingerprints.latent_prob_pos - cid_fingerprints.latent_prob_neg)\n",
    "cid_fingerprints[\"latent_prob_delta_ratio\"] = 1 - 2 * cid_fingerprints.latent_prob_delta / (cid_fingerprints.latent_prob_pos + cid_fingerprints.latent_prob_neg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
